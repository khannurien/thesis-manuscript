\chapter{Conclusion et perspectives}
\label{chapter:conclusion}

Le modèle serverless constitue un changement radical dans le cloud, en offrant aux utilisateurs la possibilité de déployer leurs applications sans se préoccuper de la gestion des ressources matérielles sous-jacentes, tout en bénéficiant d'une facturation à une granularité fine. Les fournisseurs de services, quant à eux, peuvent tirer parti des mécanismes d'allocation et de placement dynamiques pour mettre en œuvre des politiques intelligentes de gestion des ressources. À condition de prendre en considération les caractéristiques des applications déployées, et en s'appuyant sur l'hétérogénéité du matériel dans leurs centres de données, il est possible de mener des stratégies d'orchestration optimisées pour la qualité de service, tout en réduisant la consommation d'énergie de leurs infrastructures.

Dans ce dernier chapitre, nous faisons le résumé des contributions de cette thèse, avant de discuter de certaines limites que nous avons identifiées dans nos travaux. Nous concluons ce manuscrit par une discussion des travaux futurs.

\section{Résumé des contributions}
\label{section:conclusion-summary}

Le cloud est un modèle hégémonique pour le partage du temps de calcul et des capacités de stockage par Internet. C'est un environnement hautement hétérogène, construit sur des ressources matérielles et des plateformes logicielles éminemment variées, qui présentent des niveaux de performance et de coût si différents qu'ils induisent des compromis parfois difficiles à réaliser intuitivement pour un fournisseur de services.

Au cours de cette thèse, nous avons cherché à établir un modèle de coût fidèle aux enjeux pour le déploiement d'applications sur des plateformes serverless. Ces plateformes, qui allouent dynamiquement les ressources nécessaires aux applications en fonction des besoins réels, soulèvent de nouveaux questionnements pour les fournisseurs de service lorsqu'ils mettent en œuvre des politiques intelligentes de gestion des ressources. Comment peuvent-ils s'accorder sur des \gls{SLA} avec leurs clients, dès lors que les temps d'attente pour une requête sont difficiles à prévoir ? Dans quelle mesure la complexité des applications déployées impacte-t-elle cette incertitude ? L'allocation et le placement dynamiques sont-ils des leviers pertinents pour réduire la consommation d'énergie d'une infrastructure cloud ? Par ailleurs, comment mesurer les effets de leurs politiques, au regard de quelles métriques, et dans quel environnement ?

Dans notre première contribution (chapitre~\ref{chapter:herofake}), nous nous sommes appuyés sur la prédiction des performances des applications pour optimiser leur déploiement dans une infrastructure hétérogène. En exploitant des métadonnées récoltées sur les fonctions lors d'une phase préalable d'exécution hors-ligne, nous avons pu guider des décisions d'orchestration qui exploitent l'hétérogénéité de l'infrastructure de manière à limiter les violations de \gls{QoS} ainsi que la consommation d'énergie de la plateforme.

Notre deuxième contribution (chapitre~\ref{chapter:herocache}) vise à étendre notre approche à des applications complexes, qui exhibent des relations de dépendances temporelles et de données entre les fonctions qui les composent. L'incertitude sur le temps total de réalisation d'une application est renforcée par l'existence de ces dépendances, qui multiplient des allocations dynamiques qui peuvent potentiellement dégrader la \gls{QoS} par effet boule de neige. Nous avons proposé un orchestrateur conscient des données, qui prenne en compte les dépendances entre les fonctions pour consolider les applications sur un nombre réduit de nœuds à l'edge. Cette politique vise à maximiser l'utilisation des ressources, libérant une part importante de ressources matérielles dans l'infrastructure. Cela laisse la possibilité pour le fournisseur de services de mettre en œuvre des politiques d'extinction qui diminuent drastiquement la consommation d'énergie de leurs systèmes.

Enfin, nous avons exploré la problématique de l'estimation des performances d'une plateforme serverless (chapitre~\ref{chapter:herosim}). Nous avons souhaité mesurer la qualité de nos stratégies pour différentes infrastructures, lors du déploiement d'applications variées. Mettre en œuvre un environnement réaliste pour cette évaluation est un processus coûteux, qui demande du matériel et des techniques qui s'envisagent sur le temps long, dépassant le cadre de cette thèse. C'est pourquoi nous nous sommes penchés sur les approches en simulation, qui représentent un compromis intéressant entre précision et coût. Nous avons proposé, développé et distribué un simulateur sous licence libre qui permet de modéliser des environnements hétérogènes pour le modèle serverless, et de tracer le coût des décisions d'orchestration à la granularité d'une requête utilisateur.

\section{Limites des contributions}
\label{section:conclusion-limits}

Plusieurs hypothèses ont été dressées au sujet du comportement des tâches et des plateformes considérée dans nos contributions.

D'abord, nous n'avons pas pris en compte les phénomènes de \textbf{contention}~\cite{vanbeekCPUContentionPredictor2019, jacquetSweetspotVMOversubscribingCPU} que l'on peut observer lorsque des tâches sont en compétition pour des ressources matérielles partagées. Cette contention produit des \textbf{interférences}~\cite{kohAnalysisPerformanceInterference2007, vardasImprovedParallelApplication, dartoisInvestigatingMachineLearning2021} qui dégradent la qualité de service pour les utilisateurs. Par exemple, le problème des \textit{voisins bruyants} (ou \textit{noisy neighbors}) est bien connu dans le cloud~\cite{robbagbyAntimodeleVoisinBruyant} : l'activité d'un utilisateur peut dégrader les performances d'autres applications, déployées pour des utilisateurs partageant un même nœud de calcul. Ce phénomène s'observe lorsque la somme de l'utilisation des ressources atteint ou dépasse les capacités réelles des ressources matérielles du nœud. Les fournisseurs de services optent parfois pour des stratégies qui consistent à répartir les applications sur les nœuds en fonction de leurs caractéristiques en matière d'utilisation des ressources. Par exemple, il convient de distribuer sur des nœuds différents les applications respectivement intensives en calcul, en mémoire et en stockage, de manière à lisser l'usage de chacune de ces ressources et ainsi limiter les risques de les saturer sur les mêmes nœuds~\cite{khandelwalTaureauDeconstructingServerless2020}.

Nous avons étudié des applications présentant des motifs d'utilisation dits \textbf{interactifs}. Nous ne nous sommes pas intéressés à des motifs mixtes, c'est-à-dire des cas dans lesquels les usages interactifs côtoient les usages en lots. Ces situations pourraient faire émerger de nouveaux problèmes de performances liés aux phénomènes d'interférences.

Par ailleurs, dans des infrastructures distribuées comme celles des fournisseurs de services cloud, de nombreuses \textbf{pannes}~\cite{javadiFailureTraceArchive2013, galletModelSpaceCorrelatedFailures2010, BareMetal70B} se produisent et n'ont pas été prises en compte dans nos contributions. Afin de mitiger les effets néfastes des pannes matérielles, les fournisseurs de services ont recours à la réplication ou à la migration~\cite{nazaricheraghlouSurveyFaultTolerance2016}. Ces mécanismes soulèvent d'autres problèmes : par exemple, dans le cas de la réplication, se pose la question de la cohérence des données répliquées sur les différents nœuds ; dans le cas de la migration des tâches, un surcoût en latence peut dramatiquement dégrader la qualité de service. Ces éléments devraient être pris en compte dans le cadre d'études de cas à plus grande échelle que les travaux qui ont été menés au cours de cette thèse.

La plateforme serverless que nous avons décrite au cours des chapitres~\ref{chapter:herofake} et~\ref{chapter:herocache} repose sur une \textbf{phase hors-ligne} de caractérisation des fonctions à déployer. Ce mécanisme aurait bien du mal à passer à l'échelle, dans le cadre d'une plateforme généraliste, avec de nombreux utilisateurs. En outre, la complexité des algorithmes d'orchestration est également une limite forte à la capacité pour les stratégies de gestion des ressources à passer à l'échelle dans les infrastructures des acteurs commerciaux du cloud public~\cite{fuerstIluvatarFastControl2023}. Nous n'avons pas pris en compte cette composante du coût dans nos contributions. Les algorithmes que nous avons proposés sont gloutons : à chaque décision, l'espace des solutions est entièrement exploré afin de choisir celle qui minimise les coûts pour le fournisseur de services. Cela n'a pas été problématique lors de nos études de cas, qui se sont concentrées sur des infrastructures de tailles restreintes, pour un faible nombre d'applications à déployer.

\section{Travaux futurs}
\label{section:conclusion-perspectives}

Dans cette dernière section, nous discutons des perspectives à mener à court, moyen et long termes pour donner suite aux travaux engagés au cours de cette thèse. À court terme, nous donnons des éléments de réponse aux limites identifiées dans les contributions de la thèse. À moyen terme, nous proposons des pistes pour élargir la surface de couverture de nos contributions. À long terme, nous identifions des domaines de recherche dans lesquels nos approches pourraient permettre de traiter de nouveaux problèmes.

\subsection{Court terme}

Nous avons identifié la phase hors-ligne de récolte des métadonnées sur les fonctions comme une limite au passage à l'échelle de notre solution. La caractérisation des applications déployées pourrait être faite en ligne, lors des premières invocations des fonctions. On peut imaginer récolter les métadonnées des fonctions au fur et à mesure de leur exécution, en appliquant une stratégie \textit{best effort} avant d'avoir récolté suffisamment de mesures pour diriger finement les allocations de ressources et les placements de requêtes pour ces fonctions. Les mesures de temps d'initialisation, de temps d'exécution et de consommation mémoire peuvent être menées grâce à une instrumentation au niveau de l'orchestrateur. Concernant la mesure de la consommation d'énergie, des wattmètres logiciels comme PowerAPI~\cite{fieniPowerAPIPythonFramework2024}, EcoFloc~\cite{valeraEnergySavingPerspective}, Scaphandre~\footnote{\href{https://github.com/hubblo-org/scaphandre}{https://github.com/hubblo-org/scaphandre}} et d'autres~\cite{jayExperimentalComparisonSoftwarebased2023} sont disponibles sous licences libres, et pourraient être intégrés au niveau de la plateforme à la chaîne de récolte des métadonnées.

Concernant la complexité des algorithmes proposés dans cette thèse, il nous paraît intéressant d'explorer l'usage d'heuristiques pour diminuer le temps de la recherche de solutions. Nous avons commencé à travailler sur une stratégie exploitant l'apprentissage par renforcement dans le cadre d'une dualité entre prédiction et réaction. Utiliser la prédiction sur séries temporelles~\cite{bauerTimeSeriesForecasting2020} permet de réaliser une allocation proactive des ressources~\cite{parkGraphNeuralNetworkBased2024, handaouiReLeaSERReinforcementLearning2020}, au plus proche du besoin, de manière à rendre indolore le temps d'initialisation des répliques de fonctions. Dans notre architecture, un agent autonome est en charge d'ajuster les seuils au niveau desquels l'orchestrateur augmente ou diminue le nombre de répliques pour une fonction. Les pénalités sur \gls{QoS} alimentent une fonction de récompense qui permet d'entraîner l'agent à découvrir les seuils optimaux pour une infrastructure donnée, étant donnée une charge de travail prédite.

\subsection{Moyen terme}

Il serait pertinent d'étendre notre cadre d'étude en se donnant la possibilité d'utiliser des traces d'exécution réelles comme scénarios d'entrée, en plus de générer des charges de travail synthétiques. Plusieurs traces sont mises à la disposition de la communauté, notamment par des acteurs industriels majeurs comme Microsoft Azure~\cite{cortezResourceCentralUnderstanding2017a} ou Alibaba Cloud~\cite{mahmoudiSimFaaSPerformanceSimulator2021}. Les exploiter dans le cadre de l'étude du coût de bout en bout dans une plateforme serverless reste un défi ouvert, car ces traces n'incluent pas de nombreux détails essentiels à nos contributions : par souci d'anonymisation, la structure des applications déployées est caviardée ; la consommation d'énergie des tâches n'est pas mesurée, etc. Il nous semble donc important de construire des traces qui soient exploitables dans le contexte de nos contributions, c'est-à-dire des traces qui ne soient pas limitées à un horodatage des événements, mais bien des journaux détaillés qui retracent l'exécution des applications. À cette fin, il serait utile de pouvoir reproduire les comportements des applications en matière d'Entrées/Sorties, par exemple en utilisant un traceur adapté~\cite{naasEZIOTracerUnifyingKernel2021, ouarnoughiMultilevelTracerTiming}.

Nous considérons que notre modèle de coût pourrait être complété au regard des enjeux environnementaux. L'électricité n'est pas la seule ressource que consomme un centre de données~\cite{rickeCountrylevelSocialCost2018} : l'eau, par exemple, est prisée pour les systèmes de refroidissement. Il n'y a pas besoin de se rendre dans le sud des États-Unis pour réaliser qu'en été, cette ressource vient à manquer, et que cette tendance va tendre à se renforcer avec l'amenuisement des réserves d'eau douce~\cite{EauAvecRessource2024}.

Des travaux ont été proposé pour caractériser le comportement d'applications dans le cloud pour estimer les émissions de gaz à effet de serre liées à leur déploiement~\cite{courageux-sudanStudyingEndendPerformancea}. D'autres contributions proposent de nouveaux modèles de tarification prenant en compte l'empreinte carbone des traitements réalisés dans le cloud~\cite{linBridgingSustainabilityGap2024}. On peut imaginer aller plus loin : modéliser le coût total du calcul et du stockage pour la société, et le représenter fidèlement dans le temps (les émissions carbones d'aujourd'hui sont le réchauffement de demain), semblent être des défis pertinents pour notre communauté, d'autant que des exigences réglementaires émergent en matière de mesure de la consommation d'énergie et de l'empreinte carbone pour les opérateurs de centres de données~\cite{davisUptimeInstituteGlobal2022}. Des techniques ont été proposées pour agir sur l'empreinte carbone d'un centre de données en appliquant des stratégies de consolidation et d'ajustement dynamique de la fréquence des cœurs de calcul~\cite{ostapencoModelingEvaluatingOrchestrating2023}. Formaliser ce compromis comme un problème d'optimisation pourrait faire émerger des profils d'applications pour lesquelles un paramétrage donné de la plateforme donnerait le meilleur impact environnemental sous contrainte de performances.

\subsection{Long terme}

Nos contributions s'inscrivent dans des contextes cloud ou edge, mais ne s'intéressent pas au \textit{continuum} edge-cloud~\cite{jansenSPECRGReferenceArchitecture2023}. Dans ce paradigme, une partie de l'intelligence usuellement déployée dans le cloud est déplacée vers la périphérie du réseau, à l'edge, de manière à garantir des niveaux de latence suffisamment faibles pour des applications critiques comme la santé ou la robotique industrielle. Toutefois, comme nous l'avons vu dans le chapitre~\ref{chapter:herocache}, les dispositifs à l'edge sont limités en ressources et ne peuvent pas assurer l'ensemble des traitements pour la plupart des applications. Un exemple récent est celui de la version 18 d'iOS, le système d'exploitation qui équipe les smartphones Apple~\cite{WhatAppleIntelligence}. Dans cette mise à jour, le fabriquant intègre un \gls{LLM} (pour \textit{Large Language Model}) pour lequel l'inférence peut être réalisée sur l'appareil, ou déplacée vers le cloud lorsque le traitement s'avère trop lourd pour le téléphone. Se pose donc la question du compromis à réaliser entre latence, débit et consommation d'énergie, dans un contexte qui rend toujours plus saillante la question du placement des données~\cite{chikhaouiMultiobjectiveOptimizationData2021a}, sachant que la connectivité entre cloud et edge n'est pas garantie à tout moment. Approcher ce problème d'optimisation multiobjectif sous l'angle des coûts paraît être pertinent.

Une question fondamentale qu'il paraît légitime de poser en concluant ce manuscrit est celle de la recherche de performance à tout prix. Est-il bien raisonnable de vouloir calculer toujours plus vite ? La communauté \gls{HPC} fait le constat que de nombreuses tâches sont soumises à des niveaux de priorité très faibles~\cite{tirmaziBorgNextGeneration2020}. Peut-on envisager une plateforme cloud qui autorise des performances dégradées à des tarifs différenciés ? Comment travailler avec les utilisateurs pour définir des seuils pertinents, et sur la base de quelle métrique ? Des travaux proposent d'impliquer les utilisateurs dans le processus et semblent obtenir des résultats encourageants, pour une application donnée, lorsqu'une majorité des utilisateurs accepte de jouer le jeu~\cite{mokhtariDigitalSustainabilityInvolving}. Il est probable que ces résultats ne puissent pas directement s'appliquer à d'autres applications, dès lors qu'elles présentent un caractère critique (latence, débit), que leur comportement est difficilement prévisible (temps d'exécution nominal dépendant des entrées), ou qu'elles constituent des services dorsaux pour d'autres briques logicielles (bases de données, authentification). Il serait intéressant de distinguer des classes d'applications pour lesquelles des facteurs de ralentissement adéquats pourraient être établis. Pour cela, une méthodologie homogène et systématique pourrait être proposée, qui viserait à grouper les applications selon des critères objectifs afin de déterminer dans quelle mesure une dégradation de la \gls{QoS} est acceptable à l'échelle d'une requête, si toutefois cela permet un gain considérable en termes d'énergie.
