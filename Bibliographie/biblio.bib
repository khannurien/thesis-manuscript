@article{mellNISTDefinitionCloud,
	title        = {{The NIST Definition of Cloud Computing}},
	author       = {Peter Mell and Timothy Grance},
	year         = 2011,
	month        = sep,
	journal      = {National Institute of Standards and Technology Special Publication 800-145},
	doi          = {10.6028/NIST.SP.800-145},
	keywords     = {primary},
	langid       = {english}
}
@inproceedings{vaneykSPECRGCloud2018,
	title        = {A {SPEC} {RG} Cloud Group's Vision on the Performance Challenges of {FaaS} Cloud Architectures},
	author       = {{van Eyk}, Erwin and Iosup, Alexandru and Abad, Cristina L. and Grohmann, Johannes and Eismann, Simon},
	year         = 2018,
	month        = apr,
	booktitle    = {Companion of the 2018 {{ACM}}/{{SPEC International Conference}} on {{Performance Engineering}}},
	publisher    = {{ACM}},
	address      = {{Berlin Germany}},
	pages        = {21--24},
	doi          = {10.1145/3185768.3186308},
	isbn         = {978-1-4503-5629-9},
	abstract     = {As a key part of the serverless computing paradigm, Function-asa-Service (FaaS) platforms enable users to run arbitrary functions without being concerned about operational issues. However, there are several performance-related issues surrounding the state-ofthe-art FaaS platforms that can deter widespread adoption of FaaS, including sizeable overheads, unreliable performance, and new forms of the cost-performance trade-off. In this work we, the SPEC RG Cloud Group, identify six performance-related challenges that arise specifically in this FaaS model, and present our roadmap to tackle these problems in the near future. This paper aims at motivating the community to solve these challenges together.},
	langid       = {english}
}
@article{shafieiServerlessComputingSurvey2021,
	title        = {{Serverless Computing: A Survey of Opportunities, Challenges, and Applications}},
	author       = {Shafiei, Hossein and Khonsari, Ahmad and Mousavi, Payam},
	year         = 2022,
	month        = jan,
	journal      = {ACM Comput. Surv.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	doi          = {10.1145/3510611},
	issn         = {0360-0300},
	note         = {Just Accepted}
}
@article{hassanSurveyServerlessComputing2021,
	title        = {{Survey on Serverless Computing}},
	author       = {Hassan, Hassan B. and Barakat, Saman A. and Sarhan, Qusay I.},
	year         = 2021,
	month        = dec,
	journal      = {Journal of Cloud Computing},
	volume       = 10,
	number       = 1,
	pages        = 39,
	doi          = {10.1186/s13677-021-00253-7},
	issn         = {2192-113X},
	langid       = {english}
}
@inproceedings{agacheFirecrackerLightweightVirtualization,
	title        = {{Firecracker: Lightweight Virtualization for Serverless Applications}},
	author       = {Alexandru Agache and Marc Brooker and Alexandra Iordache and Anthony Liguori and Rolf Neugebauer and Phil Piwonka and Diana-Maria Popa},
	year         = 2020,
	month        = feb,
	booktitle    = {17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)},
	publisher    = {USENIX Association},
	address      = {Santa Clara, CA},
	pages        = {419--434},
	isbn         = {978-1-939133-13-7},
    url          = {https://www.usenix.org/conference/nsdi20/presentation/agache},
    urldate      = {2024-09-18},
}
@inproceedings{oakesSOCKRapidTask,
	title        = {{SOCK: Rapid Task Provisioning with Serverless-Optimized Containers}},
	author       = {Edward Oakes and Leon Yang and Dennis Zhou and Kevin Houck and Tyler Harter and Andrea Arpaci-Dusseau and Remzi Arpaci-Dusseau},
	year         = 2018,
	month        = jul,
	booktitle    = {2018 USENIX Annual Technical Conference (USENIX ATC 18)},
	publisher    = {USENIX Association},
	address      = {Boston, MA},
	pages        = {57--70},
	isbn         = {978-1-931971-44-7},
    url          = {https://www.usenix.org/conference/atc18/presentation/oakes},
    urldate      = {2024-09-18},
}
@inproceedings{akkusSANDHighPerformanceServerless,
	title        = {{SAND: Towards High-Performance Serverless Computing}},
	author       = {Akkus, Istemi Ekin and Chen, Ruichuan and Rimac, Ivica and Stein, Manuel and Satzke, Klaus and Beck, Andre and Aditya, Paarijaat and Hilt, Volker},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference},
	location     = {Boston, MA, USA},
	publisher    = {USENIX Association},
	address      = {USA},
	series       = {USENIX ATC '18},
	pages        = {923â€“935},
	doi          = {10.5555/3277355.3277444},
	isbn         = 9781931971447,
	numpages     = 13
}
@inproceedings{duCatalyzerSubmillisecondStartup2020,
	title        = {{Catalyzer: Sub-millisecond Startup for Serverless Computing with Initialization-less Booting}},
	shorttitle   = {Catalyzer},
	author       = {Du, Dong and Yu, Tianyi and Xia, Yubin and Zang, Binyu and Yan, Guanglu and Qin, Chenggang and Wu, Qixuan and Chen, Haibo},
	year         = 2020,
	month        = mar,
	booktitle    = {Proceedings of the {{Twenty-Fifth International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}},
	publisher    = {ACM},
	address      = {Lausanne Switzerland},
	pages        = {467--481},
	doi          = {10.1145/3373376.3378512},
	isbn         = {978-1-4503-7102-5},
	langid       = {english}
}
@inproceedings{ustiugovBenchmarkingAnalysisOptimization2021,
	title        = {{Benchmarking, Analysis, and Optimization of Serverless Function Snapshots}},
	author       = {Ustiugov, Dmitrii and Petrov, Plamen and Kogias, Marios and Bugnion, Edouard and Grot, Boris},
	year         = 2021,
	month        = apr,
	booktitle    = {Proceedings of the 26th {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}}},
	publisher    = {ACM},
	address      = {Virtual USA},
	pages        = {559--572},
	doi          = {10.1145/3445814.3446714},
	isbn         = {978-1-4503-8317-2},
	langid       = {english}
}
@inbook{shillakerFaasmLightweightIsolation2020,
	title        = {{FAASM: Lightweight Isolation for Efficient Stateful Serverless Computing}},
	author       = {Shillaker, Simon and Pietzuch, Peter},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference},
	publisher    = {USENIX Association},
	address      = {USA},
	doi          = {10.5555/3489146.3489174},
	isbn         = {978-1-939133-14-4},
	articleno    = 28,
	numpages     = 15
}
@article{Jiang2021TowardsDS,
	title        = {{Towards Demystifying Serverless Machine Learning Training}},
	author       = {Jiawei Jiang and Shaoduo Gan and Yue Liu and Fanlin Wang and Gustavo Alonso and Ana Klimovic and Ankit Singla and Wentao Wu and Ce Zhang},
	year         = 2021,
	month        = jun,
	journal      = {Proceedings of the 2021 International Conference on Management of Data},
	doi          = {10.1145/3448016.3459240},
	langid       = {english}
}
@inproceedings{wuTransactionalCausalConsistency2020,
	title        = {{Transactional Causal Consistency for Serverless Computing}},
	author       = {Wu, Chenggang and Sreekanti, Vikram and Hellerstein, Joseph M.},
	year         = 2020,
	month        = jun,
	booktitle    = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
	publisher    = {ACM},
	address      = {Portland OR USA},
	pages        = {83--97},
	doi          = {10.1145/3318464.3389710},
	isbn         = {978-1-4503-6735-6},
	langid       = {english}
}
@inproceedings{poppe2022moneyball,
	title        = {{Moneyball: Proactive Auto-Scaling in Microsoft Azure SQL Database Serverless}},
	author       = {Poppe, Olga and Guo, Qun and Lang, Willis and Arora, Pankaj and Oslake, Morgan and Xu, Shize and Kalhan, Ajay},
	year         = 2022,
	month        = jan,
	booktitle    = {VLDB},
	publisher    = {ACM},
	pages        = {1279--1287},
	doi          = {10.14778/3514061.3514073}
}
@article{Sreekanti2020CloudburstSF,
	title        = {{Cloudburst: Stateful Functions-as-a-Service}},
	author       = {Vikram Sreekanti and Chenggang Wu and Xiayue Charles Lin and Johann Schleier-Smith and Jose M. Faleiro and Joseph E. Gonzalez and Joseph M. Hellerstein and Alexey Tumanov},
	year         = 2020,
	journal      = {Proc. VLDB Endow.},
	volume       = 13,
	pages        = {2438--2452},
	doi          = {10.14778/3407790.3407836}
}
@article{Perron2020StarlingAS,
	title        = {{Starling: A Scalable Query Engine on Cloud Functions}},
	author       = {Matthew Perron and Raul Castro Fernandez and David J. DeWitt and Samuel Madden},
	year         = 2020,
	journal      = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
	doi          = {10.1145/3318464.3380609}
}
@article{Romero2021FaaTAT,
	title        = {{Faa\$T: A Transparent Auto-Scaling Cache for Serverless Applications}},
	author       = {Francisco Romero and Gohar Irfan Chaudhry and {\'I}{\~n}igo Goiri and Pragna Gopa and Paul Batum and Neeraja Jayant Yadwadkar and Rodrigo Fonseca and Christoforos E. Kozyrakis and Ricardo Bianchini},
	year         = 2021,
	journal      = {Proceedings of the ACM Symposium on Cloud Computing},
	doi          = {10.1145/3472883.3486974}
}
@article{Wu2018AnnaAK,
	title        = {{Anna: A KVS for Any Scale}},
	author       = {Chenggang Wu and Jose M. Faleiro and Yihan Lin and Joseph M. Hellerstein},
	year         = 2018,
	journal      = {2018 IEEE 34th International Conference on Data Engineering (ICDE)},
	pages        = {401--412},
	doi          = {10.1109/TKDE.2019.2898401}
}
@article{Klimovic2018PocketEE,
	title        = {{Pocket: Elastic Ephemeral Storage for Serverless Analytics}},
	author       = {Ana Klimovic and Ya-wen Wang and Patrick Stuedi and Animesh Kr Trivedi and Jonas Pfefferle and Christoforos E. Kozyrakis},
	year         = 2018,
	journal      = {login Usenix Mag.},
	volume       = 44,
	doi          = {10.5555/3291168.3291200}
}
@article{Chen2020FlatStoreAE,
	title        = {{FlatStore: An Efficient Log-Structured Key-Value Storage Engine for Persistent Memory}},
	author       = {Youmin Chen and Youyou Lu and Fan Yang and Qing Wang and Yang Wang and Jiwu Shu},
	year         = 2020,
	journal      = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
	doi          = {10.1145/3373376.3378515}
}
@inproceedings{vilanovaSlashingDisaggregationTax2022,
	title        = {{Slashing the Disaggregation Tax in Heterogeneous Data Centers with FractOS}},
	author       = {Vilanova, Llu{\'i}s and Maudlej, Lina and Bergman, Shai and Miemietz, Till and Hille, Matthias and Asmussen, Nils and Roitzsch, Michael and H{\"a}rtig, Hermann and Silberstein, Mark},
	year         = 2022,
	month        = mar,
	booktitle    = {Proceedings of the {{Seventeenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Rennes France},
	pages        = {352--367},
	doi          = {10.1145/3492321.3519569},
	isbn         = {978-1-4503-9162-7},
	langid       = {english}
}
@inproceedings{diamantopoulosAccelerationasauServiceCloudnativeMonteCarlo2021,
	title        = {{Acceleration-as-a-\textmu Service: A Cloud-native Monte-Carlo Option Pricing Engine on CPUs, GPUs and Disaggregated FPGAs}},
	shorttitle   = {Acceleration-as-a-{{\textmu Service}}},
	author       = {Diamantopoulos, Dionysios and Polig, Raphael and Ringlein, Burkhard and Purandare, Mitra and Weiss, Beat and Hagleitner, Christoph and Lantz, Mark and Abel, Francois},
	year         = 2021,
	month        = sep,
	booktitle    = {2021 {{IEEE}} 14th {{International Conference}} on {{Cloud Computing}} ({{CLOUD}})},
	publisher    = {IEEE},
	address      = {Chicago, IL, USA},
	pages        = {726--729},
	doi          = {10.1109/CLOUD53861.2021.00096},
	isbn         = {978-1-66540-060-2},
	langid       = {english}
}
@inproceedings{bacisBlastFunctionFPGAasaServiceSystem2020,
	title        = {{BlastFunction: An FPGA-as-a-Service System for Accelerated Serverless Computing}},
	shorttitle   = {{BlastFunction}},
	author       = {Bacis, Marco and Brondolin, Rolando and Santambrogio, Marco D.},
	year         = 2020,
	month        = mar,
	booktitle    = {2020 {{Design}}, {{Automation}} \& {{Test}} in {{Europe Conference}} \& {{Exhibition}} ({{DATE}})},
	publisher    = {IEEE},
	address      = {Grenoble, France},
	pages        = {852--857},
	doi          = {10.23919/DATE48585.2020.9116333},
	isbn         = {978-3-9819263-4-7},
	langid       = {english}
}
@article{Izraelevitz2019BasicPM,
	title        = {{Basic Performance Measurements of the Intel Optane DC Persistent Memory Module}},
	author       = {Joseph Izraelevitz and Jian Yang and Lu Zhang and Juno Kim and Xiao Liu and Amirsaman Memaripour and Yun Joon Soh and Zixuan Wang and Yi Xu and Subramanya R. Dulloor and Jishen Zhao and Steven Swanson},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1903.05714}
}
@article{Anjali2020BlendingCA,
	title        = {{Blending Containers and Virtual Machines: A Study of Firecracker and gVisor}},
	author       = {Anjali and Tyler Caraza-Harter and Michael M. Swift},
	year         = 2020,
	journal      = {Proceedings of the 16th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments},
	doi          = {10.1145/3381052.3381315}
}
@inproceedings{kuenzerUnikraftFastSpecialized2021a,
	title        = {{Unikraft: Fast, Specialized Unikernels the Easy Way}},
	shorttitle   = {Unikraft},
	author       = {Kuenzer, Simon and B{\u a}doiu, Vlad-Andrei and Lefeuvre, Hugo and Santhanam, Sharan and Jung, Alexander and Gain, Gaulthier and Soldani, Cyril and Lupu, Costin and Teodorescu, {\c S}tefan and R{\u a}ducanu, Costi and Banu, Cristian and Mathy, Laurent and Deaconescu, R{\u a}zvan and Raiciu, Costin and Huici, Felipe},
	year         = 2021,
	month        = apr,
	booktitle    = {Proceedings of the {{Sixteenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Online Event United Kingdom},
	pages        = {376--394},
	doi          = {10.1145/3447786.3456248},
	isbn         = {978-1-4503-8334-9},
	langid       = {english}
}
@inproceedings{caddenSEUSSSkipRedundant2020,
	title        = {{SEUSS: Skip Redundant Paths to Make Serverless Fast}},
	shorttitle   = {{SEUSS}},
	author       = {Cadden, James and Unger, Thomas and Awad, Yara and Dong, Han and Krieger, Orran and Appavoo, Jonathan},
	year         = 2020,
	month        = apr,
	booktitle    = {Proceedings of the {{Fifteenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Heraklion Greece},
	pages        = {1--15},
	doi          = {10.1145/3342195.3392698},
	isbn         = {978-1-4503-6882-7},
	langid       = {english}
}
@inproceedings{tanLightweightServerlessComputing2020,
	title        = {{Towards Lightweight Serverless Computing via Unikernel as a Function}},
	author       = {Tan, Bo and Liu, Haikun and Rao, Jia and Liao, Xiaofei and Jin, Hai and Zhang, Yu},
	year         = 2020,
	month        = jun,
	booktitle    = {2020 {{IEEE}}/{{ACM}} 28th {{International Symposium}} on {{Quality}} of {{Service}} ({{IWQoS}})},
	publisher    = {IEEE},
	address      = {Hang Zhou, China},
	pages        = {1--10},
	doi          = {10.1109/IWQoS49365.2020.9213020},
	isbn         = {978-1-72816-887-6},
	langid       = {english}
}
@inproceedings{wanningerIsolatingFunctionsHardware2022a,
	title        = {{Isolating Functions at the Hardware Limit with Virtines}},
	author       = {Wanninger, Nicholas C. and Bowden, Joshua J. and Shetty, Kirtankumar and Garg, Ayush and Hale, Kyle C.},
	year         = 2022,
	month        = mar,
	booktitle    = {Proceedings of the {{Seventeenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Rennes France},
	pages        = {644--662},
	doi          = {10.1145/3492321.3519553},
	isbn         = {978-1-4503-9162-7},
	langid       = {english}
}
@inproceedings{zhangKappaProgrammingFramework2020,
	title        = {{Kappa: A Programming Framework for Serverless Computing}},
	author       = {Zhang, Wen and Fang, Vivian and Panda, Aurojit and Shenker, Scott},
	year         = 2020,
	booktitle    = {Proceedings of the 11th ACM Symposium on Cloud Computing},
	location     = {Virtual Event, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {SoCC '20},
	pages        = {328â€“343},
	doi          = {10.1145/3419111.3421277},
	isbn         = 9781450381376,
	numpages     = 16
}
@article{Pons2019OnTF,
	title        = {{On the FaaS Track: Building Stateful Distributed Applications with Serverless Architectures}},
	author       = {Daniel Barcelona Pons and Marc S{\'a}nchez Artigas and Gerard Par{\'i}s and Pierre Sutra and Pedro Garc{\'i}a L{\'o}pez},
	year         = 2019,
	journal      = {Proceedings of the 20th International Middleware Conference},
	doi          = {10.1145/3361525.3361535}
}
@inproceedings{thalheimVMSHHypervisoragnosticGuest2022,
	title        = {{VMSH: Hypervisor-Agnostic Guest Overlays for VMs}},
	shorttitle   = {{VMSH}},
	author       = {Thalheim, J{\"o}rg and Okelmann, Peter and Unnibhavi, Harshavardhan and Gouicem, Redha and Bhatotia, Pramod},
	year         = 2022,
	month        = mar,
	booktitle    = {Proceedings of the {{Seventeenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Rennes France},
	pages        = {678--696},
	doi          = {10.1145/3492321.3519589},
	isbn         = {978-1-4503-9162-7},
	langid       = {english}
}
% Manque SotA scheduling %

% Ajouts %
@inbook{greenberger1962management,
	title        = {{Management and the Computer of the Future}},
	author       = {McCarthy, John},
    editor       = {Greenberger, Martin},
	year         = 1962,
    month        = mar,
	publisher    = {M.I.T. Press and Wiley, New York},
	pages        = {220--236},
	lccn         = 62013234,
    isbn         = {9780262070041},
}
@inproceedings{marshallElasticSiteUsing2010,
	title        = {{Elastic Site: Using Clouds to Elastically Extend Site Resources}},
	shorttitle   = {Elastic {{Site}}},
	author       = {Marshall, Paul and Keahey, Kate and Freeman, Tim},
	year         = 2010,
	booktitle    = {2010 10th {{IEEE}}/{{ACM International Conference}} on {{Cluster}}, {{Cloud}} and {{Grid Computing}}},
	publisher    = {IEEE},
	address      = {Melbourne, Australia},
	pages        = {43--52},
	doi          = {10.1109/CCGRID.2010.80},
	isbn         = {978-1-4244-6987-1},
	langid       = {english}
}
@book{fehlingCloudComputingPatterns2014,
	title        = {{Cloud Computing Patterns}},
	author       = {Fehling, Christoph and Leymann, Frank and Retter, Ralph and Schupeck, Walter and Arbitter, Peter},
	year         = 2014,
	publisher    = {Springer Vienna},
	address      = {Vienna},
	doi          = {10.1007/978-3-7091-1568-8},
	isbn         = {978-3-7091-1567-1},
	langid       = {english}
}
@inproceedings{weissmanDesignForceCom2009,
	title        = {{The Design of the Force.Com Multitenant Internet Application Development Platform}},
	author       = {Weissman, Craig D. and Bobrowski, Steve},
	year         = 2009,
	month        = jun,
	booktitle    = {Proceedings of the 2009 {{ACM SIGMOD International Conference}} on {{Management}} of Data},
	publisher    = {ACM},
	address      = {Providence Rhode Island USA},
	pages        = {889--896},
	doi          = {10.1145/1559845.1559942},
	isbn         = {978-1-60558-551-2},
	langid       = {english}
}
@article{vaqueroLockingSkySurvey2011,
	title        = {{Locking the Sky: A Survey on IaaS Cloud Security}},
	shorttitle   = {Locking the Sky},
	author       = {Vaquero, Luis M. and {Rodero-Merino}, Luis and Mor{\'a}n, Daniel},
	year         = 2011,
	month        = jan,
	journal      = {Computing},
	volume       = 91,
	number       = 1,
	pages        = {93--118},
	doi          = {10.1007/s00607-010-0140-x},
	issn         = {0010-485X, 1436-5057},
	langid       = {english}
}
@inproceedings{kivityKvmLinuxVirtual,
	title        = {{Kvm: The Linux Virtual Machine Monitor}},
	author       = {Kivity, Avi and Kamay, Yaniv and Laor, Dor and Lublin, Uri and Liguori, Anthon},
	year         = 2007,
	booktitle    = {Proceedings of the 2007 Ottawa Linux Symposium (OLSâ€™07)},
    volume       = {1},
    number       = {8},
    pages        = {225--230},
    year         = {2007},
    url          = {https://www.kernel.org/doc/mirror/ols2007v1.pdf#page=225},
    urldate      = {2024-09-18},
	langid       = {english}
}
@article{leiteSurveyDevopsConceptsChallenges2019,
	title        = {{A Survey of DevOps Concepts and Challenges}},
	author       = {Leite, Leonardo and Rocha, Carla and Kon, Fabio and Milojicic, Dejan and Meirelles, Paulo},
	year         = 2019,
	month        = nov,
	journal      = {ACM Comput. Surv.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 52,
	number       = 6,
	doi          = {10.1145/3359981},
	issn         = {0360-0300},
	issue_date   = {November 2020},
	articleno    = 127,
	numpages     = 35
}
@inproceedings{almeidamoraisAutoflexServiceAgnostic2013,
	title        = {{Autoflex: Service Agnostic Auto-scaling Framework for IaaS Deployment Models}},
	shorttitle   = {Autoflex},
	author       = {Almeida Morais, Fabio Jorge and Vilar Brasileiro, Francisco and Vigolvino Lopes, Raquel and Araujo Santos, Ricardo and Satterfield, W. and Rosa, L.},
	year         = 2013,
	month        = may,
	booktitle    = {2013 13th {{IEEE}}/{{ACM International Symposium}} on {{Cluster}}, {{Cloud}}, and {{Grid Computing}}},
	publisher    = {IEEE},
	address      = {Delft},
	pages        = {42--49},
	doi          = {10.1109/CCGrid.2013.74},
	isbn         = {978-0-7695-4996-5},
	langid       = {english}
}
@inproceedings{yallesRISCLESSReinforcementLearning,
	title        = {{RISCLESS: A Reinforcement Learning Strategy to Guarantee SLA on Cloud Ephemeral and Stable Resources}},
	author       = {Yalles, SidAhmed and Handaoui, Mohamed and Dartois, Jean-Emile and Barais, Olivier and dâ€™Orazio, Laurent and Boukhobza, Jalil},
	year         = 2022,
	booktitle    = {2022 30th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)},
	pages        = {83--87},
	doi          = {10.1109/PDP55904.2022.00021}
}
@article{bentalebContainerizationTechnologiesTaxonomies2022,
	title        = {{Containerization Technologies: Taxonomies, Applications and Challenges}},
	shorttitle   = {Containerization Technologies},
	author       = {Bentaleb, Ouafa and Belloum, Adam S. Z. and Sebaa, Abderrazak and {El-Maouhab}, Aouaouche},
	year         = 2022,
	month        = jan,
	journal      = {The Journal of Supercomputing},
	volume       = 78,
	number       = 1,
	pages        = {1144--1181},
	doi          = {10.1007/s11227-021-03914-1},
	issn         = {0920-8542, 1573-0484},
	langid       = {english}
}
@article{burckhardtNetheriteEfficientExecution,
	title        = {{Netherite: Efficient Execution of Serverless Workflows}},
	author       = {Burckhardt, Sebastian and Chandramouli, Badrish and Gillum, Chris and Justo, David and Kallas, Konstantinos and McMahon, Connor and Meiklejohn, Christopher S. and Zhu, Xiangfeng},
	year         = 2022,
	month        = apr,
	journal      = {Proc. VLDB Endow.},
	publisher    = {VLDB Endowment},
	volume       = 15,
	number       = 8,
	pages        = {1591â€“1604},
	doi          = {10.14778/3529337.3529344},
	issn         = {2150-8097},
	issue_date   = {April 2022},
	abstract     = {Serverless is a popular choice for cloud service architects because it can provide scalability and load-based billing with minimal developer effort. Functions-as-a-service (FaaS) are originally stateless, but emerging frameworks add stateful abstractions. For instance, the widely used Durable Functions (DF) allow developers to write advanced serverless applications, including reliable workflows and actors, in a programming language of choice. DF implicitly and continuosly persists the state and progress of applications, which greatly simplifies development, but can create an IOps bottleneck.To improve efficiency, we introduce Netherite, a novel architecture for executing serverless workflows on an elastic cluster. Netherite groups the numerous application objects into a smaller number of partitions, and pipelines the state persistence of each partition. This improves latency and throughput, as it enables workflow steps to group commit, even if causally dependent. Moreover, Netherite leverages FASTER's hybrid log approach to support larger-than-memory application state, and to enable efficient partition movement between compute hosts.Our evaluation shows that (a) Netherite achieves lower latency and higher throughput than the original DF engine, by more than an order of magnitude in some cases, and (b) that Netherite has lower latency than some commonly used alternatives, like AWS Step Functions or cloud storage triggers.},
	numpages     = 14
}
@inproceedings{jiaNightcoreEfficientScalable2021,
	title        = {{Nightcore: Efficient and Scalable Serverless Computing for Latency-Sensitive, Interactive Microservices}},
	author       = {Jia, Zhipeng and Witchel, Emmett},
	year         = 2021,
	booktitle    = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
	location     = {Virtual, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {ASPLOS '21},
	pages        = {152â€“166},
	doi          = {10.1145/3445814.3446701},
	isbn         = 9781450383172,
	numpages     = 15
}
@incollection{dragoniMicroservicesHowMake2018,
	title        = {{Microservices: How To Make Your Application Scale}},
	shorttitle   = {Microservices},
	author       = {Dragoni, Nicola and Lanese, Ivan and Larsen, Stephan Thordal and Mazzara, Manuel and Mustafin, Ruslan and Safina, Larisa},
	year         = 2018,
	booktitle    = {Perspectives of {{System Informatics}}},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	volume       = 10742,
	pages        = {95--104},
	doi          = {10.1007/978-3-319-74313-4_8},
	isbn         = {978-3-319-74312-7},
	editor       = {Petrenko, Alexander K. and Voronkov, Andrei},
	langid       = {english}
}
@incollection{mateiTransitionServerfullServerless2020,
	title        = {{Transition from Serverfull to Serverless Architecture in Cloud-Based Software Applications}},
	author       = {Matei, Oliviu and Skrzypek, Pawel and Heb, Robert and Moga, Alexandru},
	year         = 2020,
	booktitle    = {Software {{Engineering Perspectives}} in {{Intelligent Systems}}},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	volume       = 1294,
	pages        = {304--314},
	doi          = {10.1007/978-3-030-63322-6_24},
	isbn         = {978-3-030-63321-9},
	editor       = {Silhavy, Radek and Silhavy, Petr and Prokopova, Zdenka},
	langid       = {english}
}
@article{shahinContinuousIntegrationDelivery2017,
	title        = {{Continuous Integration, Delivery and Deployment: A Systematic Review on Approaches, Tools, Challenges and Practices}},
	shorttitle   = {Continuous {{Integration}}, {{Delivery}} and {{Deployment}}},
	author       = {Shahin, Mojtaba and Ali Babar, Muhammad and Zhu, Liming},
	year         = 2017,
	journal      = {IEEE Access},
	volume       = 5,
	pages        = {3909--3943},
	doi          = {10.1109/ACCESS.2017.2685629},
	issn         = {2169-3536},
	langid       = {english}
}
@inproceedings{lloydImprovingApplicationMigration2018,
	title        = {{Improving Application Migration to Serverless Computing Platforms: Latency Mitigation with Keep-Alive Workloads}},
	shorttitle   = {Improving {{Application Migration}} to {{Serverless Computing Platforms}}},
	author       = {Lloyd, Wes and Vu, Minh and Zhang, Baojia and David, Olaf and Leavesley, George},
	year         = 2018,
	month        = dec,
	booktitle    = {2018 {{IEEE}}/{{ACM International Conference}} on {{Utility}} and {{Cloud Computing Companion}} ({{UCC Companion}})},
	publisher    = {IEEE},
	address      = {Zurich},
	pages        = {195--200},
	doi          = {10.1109/UCC-Companion.2018.00056},
	isbn         = {978-1-72810-359-4},
	langid       = {english}
}
@article{golecIFaaSBusSecurityPrivacyBased2022,
	title        = {{iFaaSBus: A Security- and Privacy-Based Lightweight Framework for Serverless Computing Using IoT and Machine Learning}},
	shorttitle   = {{iFaaSBus}},
	author       = {Golec, Muhammed and Ozturac, Ridvan and Pooranian, Zahra and Gill, Sukhpal Singh and Buyya, Rajkumar},
	year         = 2022,
	month        = may,
	journal      = {IEEE Transactions on Industrial Informatics},
	volume       = 18,
	number       = 5,
	pages        = {3522--3529},
	doi          = {10.1109/TII.2021.3095466},
	issn         = {1551-3203, 1941-0050},
	langid       = {english}
}
@inproceedings{villamizarEvaluatingMonolithicMicroservice2015,
	title        = {{Evaluating the Monolithic and the Microservice Architecture Pattern to Deploy Web Applications in the Cloud}},
	author       = {Villamizar, Mario and Garces, Oscar and Castro, Harold and Verano, Mauricio and Salamanca, Lorena and Casallas, Rubby and Gil, Santiago},
	year         = 2015,
	month        = sep,
	booktitle    = {2015 10th {{Computing Colombian Conference}} ({{10CCC}})},
	publisher    = {IEEE},
	address      = {Bogota, Colombia},
	pages        = {583--590},
	doi          = {10.1109/ColumbianCC.2015.7333476},
	isbn         = {978-1-4673-9464-2},
	langid       = {english}
}
@article{atikoglu2012WorkloadAnalysis,
	title        = {{Workload Analysis of a Large-Scale Key-Value Store}},
	author       = {Atikoglu, Berk and Xu, Yuehai and Frachtenberg, Eitan and Jiang, Song and Paleczny, Mike},
	year         = 2012,
	month        = jun,
	journal      = {SIGMETRICS Perform. Eval. Rev.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 40,
	number       = 1,
	pages        = {53â€“64},
	doi          = {10.1145/2318857.2254766},
	issn         = {0163-5999},
	issue_date   = {June 2012},
	numpages     = 12
}
@inproceedings{rajesh2013Memcache,
	title        = {{Scaling Memcache at Facebook}},
	author       = {Rajesh Nishtala and Hans Fugal and Steven Grimm and Marc Kwiatkowski and Herman Lee and Harry C. Li and Ryan McElroy and Mike Paleczny and Daniel Peek and Paul Saab and David Stafford and Tony Tung and Venkateshwaran Venkataramani},
	year         = 2013,
	month        = apr,
	booktitle    = {10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)},
	publisher    = {USENIX Association},
	address      = {Lombard, IL},
	pages        = {385--398},
	isbn         = {978-1-931971-00-3}
}
@inproceedings{taibiPatternsServerlessFunctions2020,
	title        = {{Patterns for Serverless Functions (Function-as-a-Service): A Multivocal Literature Review:}},
	shorttitle   = {Patterns for {{Serverless Functions}} ({{Function-as-a-Service}})},
	author       = {Taibi, Davide and El Ioini, Nabil and Pahl, Claus and Niederkofler, Jan},
	year         = 2020,
	booktitle    = {Proceedings of the 10th {{International Conference}} on {{Cloud Computing}} and {{Services Science}}},
	publisher    = {SCITEPRESS - Science and Technology Publications},
	address      = {Prague, Czech Republic},
	pages        = {181--192},
	doi          = {10.5220/0009578501810192},
	isbn         = {978-989-758-424-4},
	langid       = {english}
}
@inproceedings{mcgrathServerlessComputingDesign2017,
	title        = {{Serverless Computing: Design, Implementation, and Performance}},
	shorttitle   = {Serverless {{Computing}}},
	author       = {McGrath, Garrett and Brenner, Paul R.},
	year         = 2017,
	month        = jun,
	booktitle    = {2017 {{IEEE}} 37th {{International Conference}} on {{Distributed Computing Systems Workshops}} ({{ICDCSW}})},
	publisher    = {IEEE},
	address      = {Atlanta, GA, USA},
	pages        = {405--410},
	doi          = {10.1109/ICDCSW.2017.36},
	isbn         = {978-1-5386-3292-5},
	langid       = {english}
}
@inproceedings{baarziMeritsViabilityMultiCloud2021,
	title        = {{On Merits and Viability of Multi-Cloud Serverless}},
	author       = {Baarzi, Ataollah Fatahi and Kesidis, George and {Joe-Wong}, Carlee and Shahrad, Mohammad},
	year         = 2021,
	month        = nov,
	booktitle    = {Proceedings of the {{ACM Symposium}} on {{Cloud Computing}}},
	publisher    = {ACM},
	address      = {Seattle WA USA},
	pages        = {600--608},
	doi          = {10.1145/3472883.3487002},
	isbn         = {978-1-4503-8638-8},
	langid       = {english}
}
@inproceedings{mohanAgileColdStartsa,
	title        = {{Agile Cold Starts for Scalable Serverless}},
	author       = {Anup Mohan and Harshad Sane and Kshitij Doshi and Saikrishna Edupuganti and Naren Nayak and Vadim Sukhomlinov},
	year         = 2019,
	month        = jul,
	booktitle    = {11th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 19)},
	publisher    = {USENIX Association},
	address      = {Renton, WA},
	pages        = 6,
	langid       = {english},
    url          = {https://www.usenix.org/conference/hotcloud19/presentation/mohan},
    urldate      = {2024-09-18},
}
@article{boukhobzaEmergingNvm,
	title        = {{Emerging NVM: A Survey on Architectural Integration and Research Challenges}},
	author       = {Boukhobza, Jalil and Rubini, St\'{e}phane and Chen, Renhai and Shao, Zili},
	year         = 2017,
	month        = nov,
	journal      = {ACM Trans. Des. Autom. Electron. Syst.},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 23,
	number       = 2,
	doi          = {10.1145/3131848},
	issn         = {1084-4309},
	issue_date   = {March 2018},
	articleno    = 14,
	numpages     = 32
}
@book{boukhobzaFlashMemory,
	title        = {{Flash Memory Integration}},
	author       = {Boukhobza, Jalil and Olivier, Pierre},
	year         = 2017,
	month        = mar,
	publisher    = {ISTE Press - Elsevier},
	pages        = 266,
	hal_id       = {hal-01557987},
	hal_version  = {v1}
}
@article{chikhaouiMultiobjectiveOptimizationData2021a,
	title        = {{Multi-Objective Optimization of Data Placement in a Storage-as-a-Service Federated Cloud}},
	author       = {Chikhaoui, Amina and Lemarchand, Laurent and Boukhalfa, Kamel and Boukhobza, Jalil},
	year         = 2021,
	month        = aug,
	journal      = {ACM Transactions on Storage},
	volume       = 17,
	number       = 3,
	pages        = {1--32},
	doi          = {10.1145/3452741},
	issn         = {1553-3077, 1553-3093},
	langid       = {english}
}
% Review %
@article{gillAINextGeneration2022a,
	title        = {{AI for next Generation Computing: Emerging Trends and Future Directions}},
	shorttitle   = {{{AI}} for next Generation Computing},
	author       = {Gill, Sukhpal Singh and Xu, Minxian and Ottaviani, Carlo and Patros, Panos and Bahsoon, Rami and Shaghaghi, Arash and Golec, Muhammed and Stankovski, Vlado and Wu, Huaming and Abraham, Ajith and Singh, Manmeet and Mehta, Harshit and Ghosh, Soumya K. and Baker, Thar and Parlikad, Ajith Kumar and Lutfiyya, Hanan and Kanhere, Salil S. and Sakellariou, Rizos and Dustdar, Schahram and Rana, Omer and Brandic, Ivona and Uhlig, Steve},
	year         = 2022,
	month        = aug,
	journal      = {Internet of Things},
	volume       = 19,
	pages        = 100514,
	doi          = {10.1016/j.iot.2022.100514},
	issn         = 25426605,
	langid       = {english}
}
@inproceedings{elsakhawyFaaS2FFrameworkDefining2020,
	title        = {{FaaS2F: A Framework for Defining Execution-SLA in Serverless Computing}},
	shorttitle   = {{FaaS2F}},
	author       = {Elsakhawy, Mohamed and Bauer, Michael},
	year         = 2020,
	month        = oct,
	booktitle    = {2020 {{IEEE Cloud Summit}}},
	publisher    = {IEEE},
	address      = {Harrisburg, PA, USA},
	pages        = {58--65},
	doi          = {10.1109/IEEECloudSummit48914.2020.00015},
	isbn         = {978-1-72818-266-7},
	langid       = {english}
}
@inproceedings{chahalSLAawareWorkloadScheduling2020,
	title        = {{SLA-aware Workload Scheduling Using Hybrid Cloud Services}},
	author       = {Chahal, Dheeraj and Palepu, Surya and Mishra, Mayank and Singhal, Rekha},
	year         = 2020,
	month        = jun,
	booktitle    = {Proceedings of the 1st {{Workshop}} on {{High Performance Serverless Computing}}},
	publisher    = {ACM},
	address      = {Virtual Event Sweden},
	pages        = {1--4},
	doi          = {10.1145/3452413.3464789},
	isbn         = {978-1-4503-8388-2},
	langid       = {english}
}
@inproceedings{schulerAIbasedResourceAllocation2021,
	title        = {{AI-based Resource Allocation: Reinforcement Learning for Adaptive Auto-scaling in Serverless Environments}},
	shorttitle   = {{AI-based Resource Allocation}},
	author       = {Schuler, Lucia and Jamil, Somaya and Kuhl, Niklas},
	year         = 2021,
	month        = may,
	booktitle    = {2021 {{IEEE}}/{{ACM}} 21st {{International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing}} ({{CCGrid}})},
	publisher    = {IEEE},
	address      = {Melbourne, Australia},
	pages        = {804--811},
	doi          = {10.1109/CCGrid51090.2021.00098},
	isbn         = {978-1-72819-586-5},
	langid       = {english}
}
@inproceedings{liuHierarchicalFrameworkCloud2017,
	title        = {{A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning}},
	author       = {Liu, Ning and Li, Zhe and Xu, Jielong and Xu, Zhiyuan and Lin, Sheng and Qiu, Qinru and Tang, Jian and Wang, Yanzhi},
	year         = 2017,
	month        = jun,
	booktitle    = {2017 {{IEEE}} 37th {{International Conference}} on {{Distributed Computing Systems}} ({{ICDCS}})},
	publisher    = {IEEE},
	address      = {Atlanta, GA, USA},
	pages        = {372--382},
	doi          = {10.1109/ICDCS.2017.123},
	isbn         = {978-1-5386-1792-2},
	langid       = {english}
}
@inproceedings{zhangNarrowingGapServerless2019,
	title        = {{Narrowing the Gap Between Serverless and Its State with Storage Functions}},
	author       = {Zhang, Tian and Xie, Dong and Li, Feifei and Stutsman, Ryan},
	year         = 2019,
	month        = nov,
	booktitle    = {Proceedings of the {{ACM Symposium}} on {{Cloud Computing}}},
	publisher    = {ACM},
	address      = {Santa Cruz CA USA},
	pages        = {1--12},
	doi          = {10.1145/3357223.3362723},
	isbn         = {978-1-4503-6973-2},
	langid       = {english}
}
@conference{barbalaceComputationalStorageWhere,
	title        = {{Computational Storage: Where Are We Today?}},
	author       = {Barbalace, Antonio and Do, Jaeyoung},
	year         = 2021,
	month        = jan,
	day          = 11,
	booktitle    = {CIDR},
	pages        = 6,
	note         = {Conference on Innovative Data Systems Research 2020, CIDR 2020 ; Conference date: 11-01-2021 Through 15-01-2021},
	language     = {English},
	langid       = {english}
}
@article{masanetRecalibratingGlobalData2020,
	title        = {{Recalibrating Global Data Center Energy-Use Estimates}},
	author       = {Masanet, Eric and Shehabi, Arman and Lei, Nuoa and Smith, Sarah and Koomey, Jonathan},
	year         = 2020,
	month        = feb,
	journal      = {Science},
	volume       = 367,
	number       = 6481,
	pages        = {984--986},
	doi          = {10.1126/science.aba3758},
	issn         = {0036-8075, 1095-9203},
	langid       = {english}
}
@article{lopesTaxonomyJobScheduling2016b,
	title        = {{A Taxonomy of Job Scheduling on Distributed Computing Systems}},
	author       = {Lopes, Raquel V. and Menasce, Daniel},
	year         = 2016,
	month        = dec,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 27,
	number       = 12,
	pages        = {3412--3428},
	doi          = {10.1109/TPDS.2016.2537821},
	issn         = {1045-9219},
	langid       = {english}
}
@article{soniMachineLearningTechniques2022,
	title        = {{Machine Learning Techniques in Emerging Cloud Computing Integrated Paradigms: A Survey and Taxonomy}},
	shorttitle   = {Machine Learning Techniques in Emerging Cloud Computing Integrated Paradigms},
	author       = {Soni, Dinesh and Kumar, Neetesh},
	year         = 2022,
	month        = sep,
	journal      = {Journal of Network and Computer Applications},
	volume       = 205,
	pages        = 103419,
	doi          = {10.1016/j.jnca.2022.103419},
	issn         = 10848045,
	langid       = {english}
}
@article{shawApplyingReinforcementLearning2022,
	title        = {{Applying Reinforcement Learning towards Automating Energy Efficient Virtual Machine Consolidation in Cloud Data Centers}},
	author       = {Shaw, Rachael and Howley, Enda and Barrett, Enda},
	year         = 2022,
	journal      = {Information Systems},
	pages        = 21,
	doi          = {10.1016/j.is.2021.101722},
	langid       = {english}
}
@article{andraeGlobalElectricityUsage2015,
	title        = {{On Global Electricity Usage of Communication Technology: Trends to 2030}},
	shorttitle   = {On {{Global Electricity Usage}} of {{Communication Technology}}},
	author       = {Andrae, Anders and Edler, Tomas},
	year         = 2015,
	month        = apr,
	journal      = {Challenges},
	volume       = 6,
	number       = 1,
	pages        = {117--157},
	doi          = {10.3390/challe6010117},
	issn         = {2078-1547},
	langid       = {english}
}
%% Ajouts dÃ©finitions
@inproceedings{jansenSPECRGReferenceArchitecture2023,
	title        = {The {{SPEC-RG Reference Architecture}} for {{The Compute Continuum}}},
	author       = {Jansen, Matthijs and {Al-Dulaimy}, Auday and Papadopoulos, Alessandro V. and Trivedi, Animesh and Iosup, Alexandru},
	year         = 2023,
	month        = may,
	booktitle    = {2023 {{IEEE}}/{{ACM}} 23rd {{International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing}} ({{CCGrid}})},
	publisher    = {IEEE},
	address      = {Bangalore, India},
	pages        = {469--484},
	doi          = {10.1109/CCGrid57682.2023.00051},
	isbn         = 9798350301199,
	copyright    = {https://doi.org/10.15223/policy-029},
	abstract     = {As the next generation of diverse workloads like autonomous driving and augmented/virtual reality evolves, computation is shifting from cloud-based services to the edge, leading to the emergence of a cloud-edge compute continuum. This continuum promises a wide spectrum of deployment opportunities for workloads that can leverage the strengths of cloud (scalable infrastructure, high reliability) and edge (energy efficient, low latencies). Despite its promises, the continuum has only been studied in silos of various computing models, thus lacking strong endto-end theoretical and engineering foundations for computing and resource management across the continuum. Consequently, developers resort to ad hoc approaches to reason about performance and resource utilization of workloads in the continuum. In this work, we conduct a first-of-its-kind systematic study of various computing models, identify salient properties, and make a case to unify them under a compute continuum reference architecture. This architecture provides an end-to-end analysis framework for developers to reason about resource management, workload distribution, and performance analysis. We demonstrate the utility of the reference architecture by analyzing two popular continuum workloads, deep learning and industrial IoT. We have developed an accompanying deployment and benchmarking framework and first-order analytical model for quantitative reasoning of continuum workloads. The framework is open-sourced and available at https://github.com/atlarge-research/continuum.},
	langid       = {english}
}
@inproceedings{corbato1962experimental,
	title        = {An experimental time-sharing system},
	author       = {Corbat{\'o}, Fernando J and Merwin-Daggett, Marjorie and Daley, Robert C},
	year         = 1962,
    publisher    = {Association for Computing Machinery},
    address      = {New York, NY, USA},
	booktitle    = {Proceedings of the May 1-3, 1962, Spring Joint Computer Conference},
    pages        = {335â€“344},
    numpages     = {10},
    location     = {San Francisco, California},
    series       = {AIEE-IRE '62 (Spring)},
	abstract     = {It is the purpose of this paper to discuss briefly the need for time-sharing, some of the implementation problems, an experimental timesharing system which has been developed for the contemporary IBM 7090, and finally a scheduling algorithm of one of us (FJC) that illustrates some of the techniques which may be employed to enhance and be analyzed for the performance limits of such a time-sharing system.},
	langid       = {english},
    doi          = {10.1145/1460833.1460871},
    isbn         = {9781450378758},
}
@article{jafarnejadghomiLoadbalancingAlgorithmsCloud2017,
	title        = {Load-Balancing Algorithms in Cloud Computing: {{A}} Survey},
	shorttitle   = {Load-Balancing Algorithms in Cloud Computing},
	author       = {Jafarnejad Ghomi, Einollah and Masoud Rahmani, Amir and Nasih Qader, Nooruldeen},
	year         = 2017,
	month        = jun,
	journal      = {Journal of Network and Computer Applications},
	volume       = 88,
	pages        = {50--71},
	doi          = {10.1016/j.jnca.2017.04.007},
	issn         = 10848045,
	abstract     = {Cloud computing is a modern paradigm to provide services through the Internet. Load balancing is a key aspect of cloud computing and avoids the situation in which some nodes become overloaded while the others are idle or have little work to do. Load balancing can improve the Quality of Service (QoS) metrics, including response time, cost, throughput, performance and resource utilization.},
	langid       = {english}
}
%% Ajouts conso d'Ã©nergie (Vincent)
@article{leeEnergyEfficientUtilization2012,
	title        = {Energy Efficient Utilization of Resources in Cloud Computing Systems},
	author       = {Lee, Young Choon and Zomaya, Albert Y.},
	year         = 2012,
	month        = may,
	journal      = {The Journal of Supercomputing},
	volume       = 60,
	number       = 2,
	pages        = {268--280},
	doi          = {10.1007/s11227-010-0421-3},
	issn         = {0920-8542, 1573-0484},
	copyright    = {http://www.springer.com/tdm},
	abstract     = {The energy consumption of under-utilized resources, particularly in a cloud environment, accounts for a substantial amount of the actual energy use. Inherently, a resource allocation strategy that takes into account resource utilization would lead to a better energy efficiency; this, in clouds, extends further with virtualization technologies in that tasks can be easily consolidated. Task consolidation is an effective method to increase resource utilization and in turn reduces energy consumption. Recent studies identified that server energy consumption scales linearly with (processor) resource utilization. This encouraging fact further highlights the significant contribution of task consolidation to the reduction in energy consumption. However, task consolidation can also lead to the freeing up of resources that can sit idling yet still drawing power. There have been some notable efforts to reduce idle power draw, typically by putting computer resources into some form of sleep/power-saving mode. In this paper, we present two energy-conscious task consolidation heuristics, which aim to maximize resource utilization and explicitly take into account both active and idle energy consumption. Our heuristics assign each task to the resource on which the energy consumption for executing the task is explicitly or implicitly minimized without the performance degradation of that task. Based on our experimental results, our heuristics demonstrate their promising energy-saving capability.},
	langid       = {english}
}
@inproceedings{vasanWorthTheirWatts2010,
	title        = {Worth Their Watts? - An Empirical Study of Datacenter Servers},
	shorttitle   = {Worth Their Watts?},
	author       = {Vasan, Arunchandar and Sivasubramaniam, Anand and Shimpi, Vikrant and Sivabalan, T. and Subbiah, Rajesh},
	year         = 2010,
	month        = jan,
	booktitle    = {{{HPCA}} - 16 2010 {{The Sixteenth International Symposium}} on {{High-Performance Computer Architecture}}},
	publisher    = {IEEE},
	address      = {Bangalore},
	pages        = {1--10},
	doi          = {10.1109/HPCA.2010.5463056},
	isbn         = {978-1-4244-5658-1},
	abstract     = {The management of power consumption in datacenters has become an important problem. This needs a systematic evaluation of the as-is scenario to identify potential areas for improvement and quantify the impact of any strategy. We present a measurement study of a production datacenter from a joint perspective of power and performance at the individual server level. Our observations help correlate power consumption of production servers with their activity, and identify easily implementable improvements. We find that production servers are underutilized from an activity perspective; are overrated from a power perspective; execute temporally similar workloads over a granularity of weeks; do not idle efficiently; and have power consumptions that are well tracked by their CPU utilizations. Our measurements suggest the following steps for improvement: staggering periodic activities on servers; enabling deeper sleep states; and provisioning based on measurement.},
	langid       = {english}
}
@inproceedings{vermaLargescaleClusterManagement2015a,
	title        = {Large-Scale Cluster Management at {{Google}} with {{Borg}}},
	author       = {Verma, Abhishek and Pedrosa, Luis and Korupolu, Madhukar and Oppenheimer, David and Tune, Eric and Wilkes, John},
	year         = 2015,
	month        = apr,
	booktitle    = {Proceedings of the {{Tenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Bordeaux France},
	pages        = {1--17},
	doi          = {10.1145/2741948.2741964},
	isbn         = {978-1-4503-3238-5},
	abstract     = {Google's Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines.},
	langid       = {english}
}
@inproceedings{kwasnickDeterminationCPUUse2011,
  title = {Determination of {{CPU}} Use Conditions},
  booktitle = {2011 {{International Reliability Physics Symposium}}},
  author = {Kwasnick, Robert and Papathanasiou, Athanasios E. and Reilly, Matthew and Rashid, Al and Zaknoon, Bashir and Falk, John},
  year = {2011},
  month = apr,
  pages = {2C.3.1-2C.3.6},
  publisher = {IEEE},
  address = {Monterey, CA, USA},
  doi = {10.1109/IRPS.2011.5784455},
  abstract = {Use condition inputs to physics-of-failure models are required to use knowledge-based qualification of ICs. Modern CPUs have multiple voltage-frequency states which vary widely in reliability stress, but it is not obvious what time in the various states to use in product qualification. We present a methodology for developing a time in state model for CPUs which combines large scale user monitoring and lab-based studies. Results for a specific CPU family, including field validation and implications for knowledge-based qualification, are discussed.},
  isbn = {978-1-4244-9113-1},
  langid = {english},
}
@article{sueurSlowSleepThat,
  title = {Slow {{Down}} or {{Sleep}}, That Is the {{Question}}},
  author = {Sueur, Etienne Le and Heiser, Gernot},
  booktitle = {2011 USENIX Annual Technical Conference (USENIX ATC 11)},
  year = {2011},
  address = {Portland, OR},
  url = {https://www.usenix.org/conference/usenixatc11/slow-down-or-sleep-question},
  urldate = {2024-09-19},
  publisher = {USENIX Association},
  month = jun,
  abstract = {Energy consumption has become a major concern for all computing systems, from servers in data-centres to mobile phones. Processor manufacturers have reacted to this by implementing power-management mechanisms in the hardware and researchers have investigated how operating systems can make use of those mechanisms to minimise energy consumption. Much of this research has focused on a single class of systems and computeintensive workloads.},
  langid = {english},
}
@incollection{shahzadInvestigatingEnergyConsumption,
  title = {Investigating {{Energy Consumption}} of an {{SRAM-based FPGA}} for {{Duty- Cycle Applications}}},
  author = {Shahzad, Khurram and Oelmann, Bengt},
  booktitle={Parallel Computing: Accelerating Computational Science and Engineering (CSE)},
  pages={548--559},
  year={2014},
  publisher={IOS Press},
  doi={10.3233/978-1-61499-381-0-548},
  abstract = {In order to conserve energy, battery powered embedded systems are typically designed with very low-power modules that offer limited computational power and communication bandwidth and therefore, are generally applicable to low-sample-rate intermittent applications. On the other hand, enabling an embedded system with a high-throughput processing resource such as an FPGA, high-throughput processing performance that is typically required in high-sample rate monitoring applications can be achieved. However, the high power consumption associated with an FPGA poses a major challenge in attaining significant lifetime for a battery-powered embedded system. In this paper, we investigate energy consumption of an SRAM-based FPGA in relation to dutycycle applications. In order to achieve long operational lifetime in an FPGA-based embedded system, the possible options to dynamically manage the power consumption are studied and discussed. The experimental results suggest that the SRAM-based FPGA, XC6SLX16 that provides ample logic resources in relation to typical high-sample rate monitoring applications, can be used in a battery operated embedded systems while minimizing the energy consumption to 2.56 mJ for inactive duration of 235 ms or above.},
  langid = {english},
}
@article{bordage2019empreinte,
  title={Empreinte environnementale du num{\'e}rique mondial},
  author={Bordage, Fr{\'e}d{\'e}ric},
  journal={Paris, greenit.fr},
  volume={9},
  year={2019}
}
@article{NumeriqueQuelsImpacts,
  title = {{Le num{\'e}rique : quels impacts environnementaux ?}},
  author = {ADEME},
  journal = {ClÃ©s pour agir},
  year = {2022},
  month = feb,
  langid = {french},
}
%%% Ajouts modÃ¨le Ã©conomique
@misc{BareMetal70B,
	title        = {From Bare Metal to a {{70B}} Model: Infrastructure Set-up and Scripts},
	shorttitle   = {From Bare Metal to a {{70B}} Model},
	author       = {{The Imbue Team}},
	abstract     = {We would like to thank Voltage Park, Dell, H5, and NVIDIA for their invaluable partnership and help with setting up our cluster. A special{\dots}},
	howpublished = {https://imbue.com/research/70b-infrastructure/},
	langid       = {american}
}
@inproceedings{wangTouchdownCloudImpact2019,
	title        = {Touchdown on the {{Cloud}}: {{The Impact}} of the {{Super Bowl}} on {{Cloud}}},
	shorttitle   = {Touchdown on the {{Cloud}}},
	author       = {Wang, Chen and Kim, Hyong},
	year         = 2019,
	month        = apr,
	booktitle    = {2019 {{IEEE Fifth International Conference}} on {{Big Data Computing Service}} and {{Applications}} ({{BigDataService}})},
	publisher    = {IEEE},
	address      = {Newark, CA, USA},
	pages        = {107--113},
	doi          = {10.1109/BigDataService.2019.00021},
	isbn         = {978-1-72810-059-3},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {The Super Bowl is the world's biggest televised sporting event. We examine the impact of the increasing online activities during the Super Bowl of year 2015-2017 on various types of Cloud systems, including the Cloud infrastructure service, the Cloud content delivery networks for live streaming, and popular web services such as on-demand video streaming service and social network applications. We probe these systems from agents deployed around the world to compare their load variations and performance changes during and after the game. Through our studies of three consecutive years, we find that Super Bowl events have impacts on the Cloud. However, the current Cloud system is still able to ensure capacity to cope with the challenges brought by traffic changes during such massive events.},
	langid       = {english}
}
@inproceedings{takMoveNotMove,
	title        = {To {{Move}} or {{Not}} to {{Move}}: {{The Economics}} of {{Cloud Computing}}},
	author       = {Tak, Byung Chul and Urgaonkar, Bhuvan and Sivasubramaniam, Anand},
	year         = 2011,
    month        = jun,
	booktitle    = {3rd USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 11)},
    publisher    = {USENIX Association},
    url          = {https://www.usenix.org/conference/hotcloud11/move-or-not-move-economics-cloud-computing},
    urldate      = {2024-09-18},
	abstract     = {Cloud-based hosting promises cost advantages over conventional in-house (on-premise) application deployment. One important question when considering a move to the cloud is whether it makes sense for `my' application to migrate to the cloud. This question is challenging to answer due to following reasons. Although many potential benefits of migrating to the cloud can be enumerated, some benefits may not apply to `my' application. Also, there can be multiple ways in which an application might make use of the facilities offered by cloud providers. Answering these questions requires an in-depth understanding of the cost implications of all the possible choices specific to `my' circumstances. In this study We identify an initial set of key factors affecting the costs of a deployement choice. Using benchmarks representing two different applications (TPC-W and TPC-E) we investigate the evolution of costs for different deployment choices. We show that application characteristics such as workload intensity, growth rate, storage capacity and software licensing costs produce complex combined effect on overall costs. We also discuss issues regarding workload variance and horizontal partitioning.},
	langid       = {english}
}
@article{alashhabImpactCoronavirusPandemic2021,
	title        = {Impact of Coronavirus Pandemic Crisis on Technologies and Cloud Computing Applications},
	author       = {Alashhab, Ziyad R. and Anbar, Mohammed and Singh, Manmeet Mahinderjit and Leau, Yu-Beng and {Al-Sai}, Zaher Ali and Abu Alhayja'a, Sami},
	year         = 2021,
	month        = mar,
	journal      = {Journal of Electronic Science and Technology},
	volume       = 19,
	number       = 1,
	pages        = 100059,
	doi          = {10.1016/j.jnlest.2020.100059},
	issn         = {1674862X},
	abstract     = {In light of the COVID-19 outbreak caused by the novel coronavirus, companies and institutions have instructed their employees to work from home as a precautionary measure to reduce the risk of contagion. Employees, however, have been exposed to different security risks because of working from home. Moreover, the rapid global spread of COVID-19 has increased the volume of data generated from various sources. Working from home depends mainly on cloud computing (CC) applications that help employees to efficiently accomplish their tasks. The cloud computing environment (CCE) is an unsung hero in the COVID-19 pandemic crisis. It consists of the fast-paced practices for services that reflect the trend of rapidly deployable applications for maintaining data. Despite the increase in the use of CC applications, there is an ongoing research challenge in the domains of CCE concerning data, guaranteeing security, and the availability of CC applications. This paper, to the best of our knowledge, is the first paper that thoroughly explains the impact of the COVID-19 pandemic on CCE. Additionally, this paper also highlights the security risks of working from home during the COVID-19 pandemic.},
	langid       = {english}
}
%% Ajouts modÃ©lisation (Vincent)

%%% Contention
@inproceedings{kohAnalysisPerformanceInterference2007,
	title        = {An {{Analysis}} of {{Performance Interference Effects}} in {{Virtual Environments}}},
	author       = {Koh, Younggyun and Knauerhase, Rob and Brett, Paul and Bowman, Mic and Wen, Zhihua and Pu, Calton},
	year         = 2007,
	month        = apr,
	booktitle    = {2007 {{IEEE International Symposium}} on {{Performance Analysis}} of {{Systems}} \& {{Software}}},
	publisher    = {IEEE},
	address      = {San Jose, CA, USA},
	pages        = {200--209},
	doi          = {10.1109/ISPASS.2007.363750},
	abstract     = {Virtualization is an essential technology in modern datacenters. Despite advantages such as security isolation, fault isolation, and environment isolation, current virtualization techniques do not provide effective performance isolation between virtual machines (VMs). Specifically, hidden contention for physical resources impacts performance differently in different workload configurations, causing significant variance in observed system throughput. To this end, characterizing workloads that generate performance interference is important in order to maximize overall utility.},
	langid       = {english}
}
@inproceedings{vanbeekCPUContentionPredictor2019,
	title        = {A {{CPU Contention Predictor}} for {{Business-Critical Workloads}} in {{Cloud Datacenters}}},
	author       = {Van Beek, Vincent and Oikonomou, Giorgos and Iosup, Alexandru},
	year         = 2019,
	month        = jun,
	booktitle    = {2019 {{IEEE}} 4th {{International Workshops}} on {{Foundations}} and {{Applications}} of {{Self}}* {{Systems}} ({{FAS}}*{{W}})},
	publisher    = {IEEE},
	address      = {Umea, Sweden},
	pages        = {56--61},
	doi          = {10.1109/FAS-W.2019.00027},
	isbn         = {978-1-72812-406-3},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Resource contention is one of the major problems in cloud datacenters. Many types of resource contention occur, with important impact on the performance and sometimes even the reliability of applications running in cloud datacenters. Cloud applications run together on the same physical machines with different workloads resulting in non-synchronized accesses to the shared resources. This leads to cases where co-hosted applications are contending for the common resources and not receiving the demanded resource amounts. In this work, we investigate the contention in CPU resources, as CPU is allowed to be over-committed by typical SLAs. We propose a CPU-contention predictor for the demanding business-critical workloads, which require low resource contention to deliver the required performance to customers. Our predictor is based on a set of regression models and metrics which we evaluate extensively. We tune the predictor with data collected from a real-world cloud operation spanning multiple datacenters and servicing businesscritical workloads.},
	langid       = {english}
}
@inproceedings{vardasImprovedParallelApplication,
	title        = {Improved {{Parallel Application Performance}} and {{Makespan}} by {{Colocation}} and {{Topology-Aware Process Mapping}}},
	author       = {Vardas, Ioannis and Wien, {\relax TU}},
	year         = 2024,
	booktitle    = {2024 IEEE/ACM 24th International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
	abstract     = {In modern, deeply hierarchical HPC systems shared resource congestion can hinder the efficient use of many cores by parallel applications and degrade performance. Such congestion is often caused when parallel processes within an application that execute similar operations share the same resources. Previous research suggests using fewer cores with better process-to-core mapping can improve applications' performance but leaves many cores unused. To utilize these cores, we colocate additional applications and map them using a topology-aware process-tocore, application-agnostic mapping algorithm. We show that these mappings significantly impact memory bandwidth and communication latency. We evaluate our approach using eight parallel applications on an HPC system with 128-core nodes, demonstrating the performance effects of mappings combined with colocation. Our goal is to determine whether colocation with topology-aware mapping is a viable alternative to typical exclusive node allocation. Our results show makespan improvements of 2.4x over exclusive allocation in an HPC system, demonstrating the potential benefits of colocation with optimized mappings.},
	langid       = {english}
}
@inproceedings{jacquetSweetspotVMOversubscribingCPU,
	title        = {{{SweetspotVM}}: {{Oversubscribing CPU}} without {{Sacrificing VM Performance}}},
	author       = {Jacquet, Pierre and Ledoux, Thomas and Rouvoy, Romain},
	year         = 2024,
	booktitle    = {2024 IEEE/ACM 24th International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
	abstract     = {The adoption of computing resources oversubscription in cloud environments is conventionally limited to a restricted subset of Virtual Machines (VMs) within the providers' offerings, primarily driven by performance considerations. So far, VMs schedulers mostly implement all-or-nothing oversubscription strategies, wherein all VM resources are either oversubscribed or remain unaltered. While the former strategy offers higher consolidation rates, the latter delivers better performance guarantees.},
	langid       = {english}
}
%%% Pannes
@incollection{galletModelSpaceCorrelatedFailures2010,
	title        = {A {{Model}} for {{Space-Correlated Failures}} in {{Large-Scale Distributed Systems}}},
	author       = {Gallet, Matthieu and Yigitbasi, Nezih and Javadi, Bahman and Kondo, Derrick and Iosup, Alexandru and Epema, Dick},
	year         = 2010,
	booktitle    = {Euro-{{Par}} 2010 - {{Parallel Processing}}},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	volume       = 6271,
	pages        = {88--100},
	doi          = {10.1007/978-3-642-15277-1_10},
	editor       = {D'Ambra, Pasqua and Guarracino, Mario and Talia, Domenico},
	abstract     = {Distributed systems such as grids, peer-to-peer systems, and even Internet DNS servers have grown significantly in size and complexity in the last decade. This rapid growth has allowed distributed systems to serve a large and increasing number of users, but has also made resource and system failures inevitable. Moreover, perhaps as a result of system complexity, in distributed systems a single failure can trigger within a short time span several more failures, forming a group of time-correlated failures. To eliminate or alleviate the significant effects of failures on performance and functionality, the techniques for dealing with failures require good failure models. However, not many such models are available, and the available models are valid for few or even a single distributed system. In contrast, in this work we propose a model that considers groups of time-correlated failures and is valid for many types of distributed systems. Our model includes three components, the group size, the group inter-arrival time, and the resource downtime caused by the group. To validate this model, we use failure traces corresponding to fifteen distributed systems. We find that space-correlated failures are dominant in terms of resource downtime in seven of the fifteen studied systems. For each of these seven systems, we provide a set of model parameters that can be used in research studies or for tuning distributed systems. Last, as a result of our work six of the studied traces have been made available through the Failure Trace Archive (http://fta.inria.fr).},
	langid       = {english}
}
@article{javadiFailureTraceArchive2013,
	title        = {The {{Failure Trace Archive}}: {{Enabling}} the Comparison of Failure Measurements and Models of Distributed Systems},
	shorttitle   = {The {{Failure Trace Archive}}},
	author       = {Javadi, Bahman and Kondo, Derrick and Iosup, Alexandru and Epema, Dick},
	year         = 2013,
	month        = aug,
	journal      = {Journal of Parallel and Distributed Computing},
	volume       = 73,
	number       = 8,
	pages        = {1208--1223},
	doi          = {10.1016/j.jpdc.2013.04.002},
	issn         = {07437315},
	abstract     = {With the increasing presence, scale, and complexity of distributed systems, resource failures are becoming an important and practical topic of computer science research. While numerous failure models and failure-aware algorithms exist, their comparison has been hampered by the lack of public failure data sets and data processing tools. To facilitate the design, validation, and comparison of fault-tolerant models and algorithms, we have created the Failure Trace Archive (FTA)---an online, public repository of failure traces collected from diverse parallel and distributed systems. In this work, we first describe the design of the archive, in particular of the standard FTA data format, and the design of a toolbox that facilitates automated analysis of trace data sets. We also discuss the use of the FTA for various current and future purposes. Second, after applying the toolbox to nine failure traces collected from distributed systems used in various application domains (e.g., HPC, Internet operation, and various online applications), we present a comparative analysis of failures in various distributed systems. Our analysis presents various statistical insights and typical statistical modeling results for the availability of individual resources in various distributed systems. The analysis results underline the need for public availability of trace data from different distributed systems. Last, we show how different interpretations of the meaning of failure data can result in different conclusions for failure modeling and job scheduling in distributed systems. Our results for different interpretations show evidence that there may be a need for further revisiting existing failure-aware algorithms, when applied for general rather than for domain-specific distributed systems. {\copyright} 2013 Elsevier Inc. All rights reserved.},
	langid       = {english}
}
@article{nazaricheraghlouSurveyFaultTolerance2016,
    title = {A Survey of Fault Tolerance Architecture in Cloud Computing},
    author = {Nazari Cheraghlou, Mehdi and {Khadem-Zadeh}, Ahmad and Haghparast, Majid},
    year = {2016},
    month = feb,
    journal = {Journal of Network and Computer Applications},
    volume = {61},
    pages = {81--92},
    issn = {10848045},
    doi = {10.1016/j.jnca.2015.10.004},
    abstract = {Utilizing cloud computing services has had numerous advantages such as the reduction of costs, development of efficiency, central promotion of soft wares, compatibility of various formats, unlimited storage capacity, easy access to services at any time and from any location and, most importantly, the independency of these services from the hardware. It should be mentioned that the provision of various cloud computing services is faced with problems and challenges that the fault tolerance can be mentioned as the main restrictions.},
    langid = {english},
}

%% Ajouts caractÃ©risation

%%% I/O
@inproceedings{naasEZIOTracerUnifyingKernel2021,
  title = {{{EZIOTracer}}: Unifying Kernel and User Space {{I}}/{{O}} Tracing for Data-Intensive Applications},
  shorttitle = {{{EZIOTracer}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Challenges}} and {{Opportunities}} of {{Efficient}} and {{Performant Storage Systems}}},
  author = {Naas, Mohammed Islam and Trahay, Fran{\c c}ois and Colin, Alexis and Olivier, Pierre and Rubini, St{\'e}phane and Singhoff, Frank and Boukhobza, Jalil},
  year = {2021},
  month = apr,
  pages = {1--11},
  publisher = {ACM},
  address = {Online Event United Kingdom},
  doi = {10.1145/3439839.3458731},
  isbn = {978-1-4503-8302-8},
  langid = {english},
}
@inproceedings{ouarnoughiMultilevelTracerTiming,
  title = {A {{Multilevel I}}/{{O Tracer}} for {{Timing}} and {{Performance Analysis}} of {{Storage Systems}} in {{IaaS Cloud}}},
  author = {Ouarnoughi, Hamza and Boukhobza, Jalil and Singhoff, Frank},
  editor       = {Marisol Garc{\'{\i}}a{-}Valls and Tommaso Cucinotta},
  booktitle    = {Proceedings of the 3rd {IEEE} International Workshop on Real-time and distributed computing in emerging applications},
  series = {{REACTION} 2014},
  location = {Rome Italy},
  month = dec,
  publisher    = {Universidad Carlos {III} de Madrid},
  year         = {2014},
  url          = {https://hdl.handle.net/10016/19685},
  abstract = {Data centers are more and more relying on hybrid storage systems consisting of flash memory based storage devices and traditional hard disk drives. Optimal data placement in such hybrid storage systems is a very important issue in the domain of cloud computing and virtualization. This is specially the case when users need that storage systems enforce Quality of Service requirements on I/Os performed, for example for multimedia applications. To characterize Virtual Machine (VM) I/O workload properties such as timing predictability or throughput, monitoring services are necessary on such new architectures. This article presents a multilevel I/O tracer for virtual machines that relies on and complement different state-of-the-art tools. It produces I/O traces at different levels of the Linux I/O software stack. The I/O tracer gives an exhaustive information that allows administrators to precisely characterize virtual machine I/O behavior in terms of percentage of read/write I/Os, percentage of random/sequential, I/O request inter-arrival time, etc. This tool is the first piece towards a middleware whose purpose is to meet user QoS requirements thanks to optimal data placement and migration policies in a hybrid storage system in the context of an IaaS Cloud.},
  langid = {english},
}

%%% Oversubscription / overcommitment
@inproceedings{bashirTakeItLimit2021,
	title        = {Take It to the Limit: Peak Prediction-Driven Resource Overcommitment in Datacenters},
	shorttitle   = {Take It to the Limit},
	author       = {Bashir, Noman and Deng, Nan and Rzadca, Krzysztof and Irwin, David and Kodak, Sree and Jnagal, Rohit},
	year         = 2021,
	month        = apr,
	booktitle    = {Proceedings of the {{Sixteenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Online Event United Kingdom},
	pages        = {556--573},
	doi          = {10.1145/3447786.3456259},
	isbn         = {978-1-4503-8334-9},
	abstract     = {To increase utilization, datacenter schedulers often overcommit resources where the sum of resources allocated to the tasks on a machine exceeds its physical capacity. Setting the right level of overcommitment is a challenging problem: low overcommitment leads to wasted resources, while high overcommitment leads to task performance degradation. In this paper, we take a first principles approach to designing and evaluating overcommit policies by asking a basic question: assuming complete knowledge of each task's future resource usage, what is the safest overcommit policy that yields the highest utilization? We call this policy the peak oracle. We then devise practical overcommit policies that mimic this peak oracle by predicting future machine resource usage. We simulate our overcommit policies using the recentlyreleased Google cluster trace, and show that they result in higher utilization and less overcommit errors than policies based on per-task allocations. We also deploy these policies to machines inside Google's datacenters serving its internal production workload. We show that our overcommit policies increase these machines' usable CPU capacity by 10-16\% compared to no overcommitment.},
	langid       = {english}
}
@inproceedings{cortezResourceCentralUnderstanding2017a,
	title        = {Resource {{Central}}: {{Understanding}} and {{Predicting Workloads}} for {{Improved Resource Management}} in {{Large Cloud Platforms}}},
	shorttitle   = {Resource {{Central}}},
	author       = {Cortez, Eli and Bonde, Anand and Muzio, Alexandre and Russinovich, Mark and Fontoura, Marcus and Bianchini, Ricardo},
	year         = 2017,
	month        = oct,
	booktitle    = {Proceedings of the 26th {{Symposium}} on {{Operating Systems Principles}}},
	publisher    = {ACM},
	address      = {Shanghai China},
	pages        = {153--167},
	doi          = {10.1145/3132747.3132772},
	isbn         = {978-1-4503-5085-3},
	abstract     = {Cloud research to date has lacked data on the characteristics of the production virtual machine (VM) workloads of large cloud providers. A thorough understanding of these characteristics can inform the providers' resource management systems, e.g. VM scheduler, power manager, server health manager. In this paper, we first introduce an extensive characterization of Microsoft Azure's VM workload, including distributions of the VMs' lifetime, deployment size, and resource consumption. We then show that certain VM behaviors are fairly consistent over multiple lifetimes, i.e. history is an accurate predictor of future behavior. Based on this observation, we next introduce Resource Central (RC), a system that collects VM telemetry, learns these behaviors offline, and provides predictions online to various resource managers via a general client-side library. As an example of RC's online use, we modify Azure's VM scheduler to leverage predictions in oversubscribing servers (with oversubscribable VM types), while retaining high VM performance. Using real VM traces, we then show that the prediction-informed schedules increase utilization and prevent physical resource exhaustion. We conclude that providers can exploit their workloads' characteristics and machine learning to improve resource management substantially.},
	langid       = {english}
}
%%% Overbooking
@inproceedings{tomasImprovingCloudInfrastructure2013,
	title        = {Improving Cloud Infrastructure Utilization through Overbooking},
	author       = {Tom{\'a}s, Luis and Tordsson, Johan},
	year         = 2013,
	month        = aug,
	booktitle    = {Proceedings of the 2013 {{ACM Cloud}} and {{Autonomic Computing Conference}}},
	publisher    = {ACM},
	address      = {Miami Florida USA},
	pages        = {1--10},
	doi          = {10.1145/2494621.2494627},
	isbn         = {978-1-4503-2172-3},
	abstract     = {Despite the potential given by the combination of multitenancy and virtualization, resource utilization in today's data centers is still low. We identify three key characteristics of cloud services and infrastructure as-a-service management practices: burstiness in service workloads, fluctuations in virtual machine resource usage over time, and virtual machines being limited to pre-defined sizes only. Based on these characteristics, we propose scheduling and admission control algorithms that incorporate resource overbooking to improve utilization. A combination of modeling, monitoring, and prediction techniques is used to avoid overpassing the total infrastructure capacity. A performance evaluation using a mixture of workload traces demonstrates the potential for significant improvements in resource utilization while still avoiding overpassing the total capacity.},
	langid       = {english}
}
%%% ModÃ©lisation de la conso
@article{orgerieSurveyTechniquesImproving2014,
	title        = {A Survey on Techniques for Improving the Energy Efficiency of Large-Scale Distributed Systems},
	author       = {Orgerie, Anne-Cecile and de Assuncao, Marcos Dias and Lefevre, Laurent},
	year         = 2014,
	month        = apr,
	journal      = {ACM Computing Surveys},
	volume       = 46,
	number       = 4,
	pages        = {1--31},
	doi          = {10.1145/2532637},
	issn         = {0360-0300, 1557-7341},
	abstract     = {The great amounts of energy consumed by large-scale computing and network systems, such as data centers and supercomputers, have been a major source of concern in a society increasingly reliant on information technology. Trying to tackle this issue, the research community and industry have proposed myriad techniques to curb the energy consumed by IT systems. This article surveys techniques and solutions that aim to improve the energy efficiency of computing and network resources. It discusses methods to evaluate and model the energy consumed by these resources, and describes techniques that operate at a distributed system level, trying to improve aspects such as resource allocation, scheduling, and network traffic management. This work aims to review the state of the art on energy efficiency and to foster research on schemes to make network and computing resources more efficient.},
	langid       = {english}
}
%%% WattmÃ¨tres logiciels
@phdthesis{valeraEnergySavingPerspective,
	title        = {An Energy Saving Perspective for Distributed Environments: {{Deployment}}, Scheduling and Simulation with Multidimensional Entities for {{Software}} and {{Hardware}}},
	author       = {Valera, Hernan Humberto Alvarez},
	langid       = {english}
}
@article{fieniPowerAPIPythonFramework2024,
	title        = {{{PowerAPI}}: {{A Python}} Framework for Buildingsoftware-Defined Power Meters},
	shorttitle   = {{PowerAPI}},
	author       = {Fieni, Guillaume and Acero, Daniel Romero and Rust, Pierre and Rouvoy, Romain},
	year         = 2024,
	month        = jun,
	journal      = {Journal of Open Source Software},
	volume       = 9,
	number       = 98,
	pages        = 6670,
	doi          = {10.21105/joss.06670},
	issn         = {2475-9066},
	copyright    = {http://creativecommons.org/licenses/by/4.0/},
	abstract     = {Software that we use daily for accessing digital services from connected devices has a negative impact on the environment as it consumes energy. These digital services, hosted by physical machines around the world, also contribute to planetary pollution. Unfortunately, providers of these online services mostly focus on hardware efficiency to reduce the environmental impact without considering the software they host. For this reason, we propose PowerAPI (G. Fieni, Romero, et al., 2024), a software-defined solution that delivers real-time estimations of software power consumption to spot opportunities to reduce it and therefore to limit their impact on the planet beyond hardware improvements.},
	langid       = {english}
}
@inproceedings{jayExperimentalComparisonSoftwarebased2023,
	title        = {An Experimental Comparison of Software-Based Power Meters: Focus on {{CPU}} and {{GPU}}},
	shorttitle   = {An Experimental Comparison of Software-Based Power Meters},
	author       = {Jay, Mathilde and Ostapenco, Vladimir and Lefevre, Laurent and Trystram, Denis and Orgerie, Anne-C{\'e}cile and Fichel, Benjamin},
	year         = 2023,
	month        = may,
	booktitle    = {2023 {{IEEE}}/{{ACM}} 23rd {{International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing}} ({{CCGrid}})},
	publisher    = {IEEE},
	address      = {Bangalore, India},
	pages        = {106--118},
	doi          = {10.1109/CCGrid57682.2023.00020},
	isbn         = 9798350301199,
	copyright    = {https://doi.org/10.15223/policy-029},
	abstract     = {The global energy demand for digital activities is constantly growing. Computing nodes and cloud services are at the heart of these activities. Understanding their energy consumption is an important step towards reducing it. On one hand, physical power meters are very accurate in measuring energy but they are expensive, difficult to deploy on a large scale, and are not able to provide measurements at the service level. On the other hand, power models and vendor-specific internal interfaces are already available or can be implemented on existing systems. Plenty of tools, called software-based power meters, have been developed around the concepts of power models and internal interfaces, in order to report the power consumption at levels ranging from the whole computing node to applications and services. However, we have found that it can be difficult to choose the right tool for a specific need. In this work, we qualitatively and experimentally compare several software-based power meters able to deal with CPU or GPU-based infrastructures. For this purpose, we evaluate them against high-precision physical power meters while executing various intensive workloads. We extend this empirical study to highlight the strengths and limitations of each software-based power meter.},
	langid       = {english}
}
%%% Workloads
@inproceedings{tirmaziBorgNextGeneration2020,
	title        = {Borg: The next Generation},
	shorttitle   = {Borg},
	author       = {Tirmazi, Muhammad and Barker, Adam and Deng, Nan and Haque, Md E. and Qin, Zhijing Gene and Hand, Steven and {Harchol-Balter}, Mor and Wilkes, John},
	year         = 2020,
	month        = apr,
	booktitle    = {Proceedings of the {{Fifteenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Heraklion Greece},
	pages        = {1--14},
	doi          = {10.1145/3342195.3387517},
	isbn         = {978-1-4503-6882-7},
	abstract     = {This paper analyzes a newly-published trace that covers 8 different Borg [35] clusters for the month of May 2019. The trace enables researchers to explore how scheduling works in large-scale production compute clusters. We highlight how Borg has evolved and perform a longitudinal comparison of the newly-published 2019 trace against the 2011 trace, which has been highly cited within the research community.},
	langid       = {english}
}
%%% CoÃ»t sociÃ©tÃ©
@article{rickeCountrylevelSocialCost2018,
	title        = {Country-Level Social Cost of Carbon},
	author       = {Ricke, Katharine and Drouet, Laurent and Caldeira, Ken and Tavoni, Massimo},
	year         = 2018,
	month        = oct,
	journal      = {Nature Climate Change},
	volume       = 8,
	number       = 10,
	pages        = {895--900},
	doi          = {10.1038/s41558-018-0282-y},
	issn         = {1758-678X, 1758-6798},
	langid       = {english}
}
@article{ostapencoModelingEvaluatingOrchestrating2023,
  title = {Modeling, Evaluating, and Orchestrating Heterogeneous Environmental Leverages for Large-Scale Data Center Management},
  author = {Ostapenco, Vladimir and Lef{\`e}vre, Laurent and Orgerie, Anne-C{\'e}cile and Fichel, Benjamin},
  year = {2023},
  month = jul,
  journal = {The International Journal of High Performance Computing Applications},
  volume = {37},
  number = {3-4},
  pages = {328--350},
  issn = {1094-3420, 1741-2846},
  doi = {10.1177/10943420231172978},
  abstract = {Data centers are very energy-intensive facilities that can generate various environmental impacts. Numerous energy, power, and environmental leverages exist and can help cloud providers and data center managers to reduce some of these impacts. But dealing, with such heterogeneous leverages can be a challenging task that requires some support from a dedicated framework. This article presents a new approach for modeling, evaluating and orchestrating a large set of technological and logistical leverages. Our framework is based on leverages modeling and Gantt chart leverages mapping. First experimental results based on selected scenarios show the pertinence of the proposed approach in terms of management facilities and potential impacts reduction.},
  langid = {english},
}
@inproceedings{courageux-sudanStudyingEndendPerformancea,
  title = {Studying the End-to-End Performance, Energy Consumption and Carbon Footprint of Fog Applications},
  author = {{Courageux-Sudan}, Cl{\'e}ment and Orgerie, Anne-C{\'e}cile and Quinson, Martin},
  booktitle={ISCC: IEEE Symposium on Computers and Communications},
  year={2024},
  abstract = {The deployment of applications closer to end-users through fog computing has shown promise in improving network communication times and reducing contention. However, the use of fog applications such as microservices necessitates intricate network interactions among heterogeneous devices. Consequently, understanding the impact of different application and infrastructure parameters on performance becomes crucial. Current literature either offers end-to-end models that lack granularity and validation or fine-grained models that only consider a portion of the infrastructure. Our research first compares experimentally the accuracy of the existing integrated frameworks. We then combine one of these tools with a collection of validated models to obtain comprehensive metrics regarding microservice applications operating in the fog. Through a usecase, we demonstrate the effectiveness of our approach in investigating fog environments, from examining application latencies to greenhouse gas emissions.},
  langid = {english},
}
%% Ajouts historique
@article{hayesCloudComputing2008,
	title        = {Cloud Computing},
	author       = {Hayes, Brian},
	year         = 2008,
	month        = jul,
	journal      = {Communications of the ACM},
	volume       = 51,
	number       = 7,
	pages        = {9--11},
	doi          = {10.1145/1364782.1364786},
	issn         = {0001-0782, 1557-7317},
	abstract     = {As software migrates from local PCs to distant Internet servers, users and developers alike go along for the ride.},
	langid       = {english}
}
@article{andersonServerlessNetworkFile,
	title        = {Serverless {{Network File Systems}}},
	author       = {Anderson, E and Dahlin, D and Neefe, Jeanna M and Patterson, A and Roselli, S and Wang, Y},
	abstract     = {In this paper, we propose a new paradigm for network file system design, serverless network ,file systems. While traditional netwc{\textasciitilde}rk file systems rely on a central server machine, a serverless system utilizes workstations cooperating as peers to provide all file system services. Any machine in the system can store, cache, or control any block of' data. Our approach uses this location illdepelldeIICe, in combination with fast local area networks, to proviclc better performance and scalability than traditional file systems. Further, because any machine in the system can assume the responsibilities of a failed component, our serverless clesign also provides high availability via redundant data storage. To demonstrate our approach, we have implemented a prototype serverless network file system called xFS. Preliminary performance measurements suggest that our architecture achieves its goal of scalability. For instance, in a 32-node xI\% system with 32 active clients, each client receives nearly as much read or write throughput as it would see if it were the only active client.},
	langid       = {english}
}
@article{meyerVirtualMachineTimesharing1970,
	title        = {A Virtual Machine Time-Sharing System},
	author       = {Meyer, R. A. and Seawright, L. H.},
	year         = 1970,
	journal      = {IBM Systems Journal},
	volume       = 9,
	number       = 3,
	pages        = {199--218},
	doi          = {10.1147/sj.93.0199},
	issn         = {0018-8670},
	langid       = {english}
}
@article{vaneykSPECRGReferenceArchitecture2019,
	title        = {The {{SPEC-RG Reference Architecture}} for {{FaaS}}: {{From Microservices}} and {{Containers}} to {{Serverless Platforms}}},
	shorttitle   = {The {{SPEC-RG Reference Architecture}} for {{FaaS}}},
	author       = {Van Eyk, Erwin and Grohmann, Johannes and Eismann, Simon and Bauer, Andre and Versluis, Laurens and Toader, Lucian and Schmitt, Norbert and Herbst, Nikolas and Abad, Cristina L. and Iosup, Alexandru},
	year         = 2019,
	month        = nov,
	journal      = {IEEE Internet Computing},
	volume       = 23,
	number       = 6,
	pages        = {7--18},
	doi          = {10.1109/MIC.2019.2952061},
	issn         = {1089-7801, 1941-0131},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Microservices, containers, and serverless computing belong to a trend toward applications composed of many small, self-contained, and automatically managed components. Core to serverless computing, Function-as-a-Service (FaaS) platforms employ state-of-the-art container technology and microservices-based architectures to enable users to manage complex applications without the need for systems-level expertise. Victim of its own success, and partially due to proprietary technology, currently the community has a limited overview of these platforms. To address this, we propose a reference architecture and ecosystem for FaaS platforms. Based on a year-long survey of real-world platforms conducted within the SPEC-RG Cloud Group, we highlight specific components and identify common operational patterns.},
	langid       = {english}
}
@article{herbstElasticityCloudComputing,
	title        = {Elasticity in {{Cloud Computing}}: {{What It Is}}, and {{What It Is Not}}},
	author       = {Herbst, Nikolas Roman and Kounev, Samuel and Reussner, Ralf},
	booktitle = {10th International Conference on Autonomic Computing (ICAC 13)},
	year = {2013},
	isbn = {978-1-931971-02-7},
	address = {San Jose, CA},
	pages = {23--27},
	url = {https://www.usenix.org/conference/icac13/technical-sessions/presentation/herbst},
    urldate = {2024-09-18},
	publisher = {USENIX Association},
	month = jun,
	abstract     = {Originating from the field of physics and economics, the term elasticity is nowadays heavily used in the context of cloud computing. In this context, elasticity is commonly understood as the ability of a system to automatically provision and deprovision computing resources on demand as workloads change. However, elasticity still lacks a precise definition as well as representative metrics coupled with a benchmarking methodology to enable comparability of systems. Existing definitions of elasticity are largely inconsistent and unspecific, which leads to confusion in the use of the term and its differentiation from related terms such as scalability and efficiency; the proposed measurement methodologies do not provide means to quantify elasticity without mixing it with efficiency or scalability aspects. In this short paper, we propose a precise definition of elasticity and analyze its core properties and requirements explicitly distinguishing from related terms such as scalability and efficiency. Furthermore, we present a set of appropriate elasticity metrics and sketch a new elasticity tailored benchmarking methodology addressing the special requirements on workload design and calibration.},
	langid       = {english}
}
@inproceedings{straesserWhyItNot2022,
	title        = {Why {{Is It Not Solved Yet}}?: {{Challenges}} for {{Production-Ready Autoscaling}}},
	shorttitle   = {Why {{Is It Not Solved Yet}}?},
	author       = {Straesser, Martin and Grohmann, Johannes and Von Kistowski, J{\'o}akim and Eismann, Simon and Bauer, Andr{\'e} and Kounev, Samuel},
	year         = 2022,
	month        = apr,
	booktitle    = {Proceedings of the 2022 {{ACM}}/{{SPEC}} on {{International Conference}} on {{Performance Engineering}}},
	publisher    = {ACM},
	address      = {Beijing China},
	pages        = {105--115},
	doi          = {10.1145/3489525.3511680},
	isbn         = {978-1-4503-9143-6},
	abstract     = {Autoscaling is a task of major importance in the cloud computing domain as it directly affects both operating costs and customer experience. Although there has been active research in this area for over ten years now, there is still a significant gap between the proposed methods in the literature and the deployed autoscalers in practice. Hence, many research autoscalers do not find their way into production deployments. This paper describes six core challenges that arise in production systems that are still not solved by most research autoscalers. We illustrate these problems through experiments in a realistic cloud environment with a real-world multi-service business application and show that commonly used autoscalers have various shortcomings. In addition, we analyze the behavior of overloaded services and show that these can be problematic for existing autoscalers. Generally, we analyze that these challenges are only insufficiently addressed in the literature and conclude that future scaling approaches should focus on the needs of production systems.},
	langid       = {english}
}
%% Ajouts optimisation
@book{ehrgottMulticriteriaOptimization882005,
	title        = {Multicriteria Optimization: With 88 Figures and 12 Tables},
	shorttitle   = {Multicriteria Optimization},
	author       = {Ehrgott, Matthias},
	year         = 2005,
	publisher    = {Springer},
	address      = {Berlin Heidelberg New York},
	isbn         = {978-3-540-21398-7},
	edition      = {Second edition},
	abstract     = {Decision makers in many areas, from industry to engineering and the social sector, face an increasing need to consider multiple, conflicting objectives in their decision processes. In many cases these real world decision problems can be formulated as multicriteria mathematical optimization models. The solution of such models requires appropriate techniques to compute so called efficient, or Pareto optimal, or compromise solutions that - unlike traditional mathematical programming methods - take the contradictory nature of the criteria into account. This book provides the necessary mathematical foundation of multicriteria optimization to solve nonlinear, linear and combinatorial problems with multiple criteria. Motivational examples illustrate the use of multicriteria optimization in practice. Numerous illustrations and exercises as well as an extensive bibliography are provided. In the new editiona chapter on optimality conditions has been added. The linear programming part has been extended andincludesnew developments. Moreover,motivational examples are nowintroducing the majority ofchapters. TOC:Multicriteria Optimization:Introduction.-Efficient Solutions and Nondominated Points.- Optimality Conditions.-Weighted Sum Scalarization.-Other Scalarization Methods.-Nonscalarizing Techniques.-Multiobjective Linear Programming:Introduction.- Simplex Based Techniques.-Solving MOLPs in Objective Space.-Other Methods.- Multiobjective Combinatorial Optimization:Introduction.-General Purpose Methods.- Special Purpose Methods.-(Meta)Heuristics},
	langid       = {english}
}
@article{marlerWeightedSumMethod2010,
	title        = {The Weighted Sum Method for Multi-Objective Optimization: New Insights},
	shorttitle   = {The Weighted Sum Method for Multi-Objective Optimization},
	author       = {Marler, R. Timothy and Arora, Jasbir S.},
	year         = 2010,
	month        = jun,
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = 41,
	number       = 6,
	pages        = {853--862},
	doi          = {10.1007/s00158-009-0460-7},
	issn         = {1615-147X, 1615-1488},
	copyright    = {http://www.springer.com/tdm},
	abstract     = {As a common concept in multi-objective optimization, minimizing a weighted sum constitutes an independent method as well as a component of other methods. Consequently, insight into characteristics of the weighted sum method has far reaching implications. However, despite the many published applications for this method and the literature addressing its pitfalls with respect to depicting the Pareto optimal set, there is little comprehensive discussion concerning the conceptual significance of the weights and techniques for maximizing the effectiveness of the method with respect to a priori articulation of preferences. Thus, in this paper, we investigate the fundamental significance of the weights in terms of preferences, the Pareto optimal set, and objective-function values. We determine the factors that dictate which solution point results from a particular set of weights. Fundamental deficiencies are identified in terms of a priori articulation of preferences, and guidelines are provided to help avoid blind use of the method.},
	langid       = {english}
}
%% Ajouts ouverture

@inproceedings{linBridgingSustainabilityGap2024,
  title = {Bridging the {{Sustainability Gap}} in {{Serverless}} through {{Observability}} and {{Carbon-Aware Pricing}}},
  author = {Lin, Changyuan and Shahrad, Mohammad},
  year = {2024},
  booktitle = {Proceedings of the 3rd Workshop on Sustainable Computer Systems},
  location = {Santa Cruz California},
  series = {HotCarbon '24},
  abstract = {Serverless computing has become a mainstream cloud computing paradigm due to its high scalability, ease of server management, and cost-effectiveness. With cloud data centers' carbon footprint rising sharply, understanding and minimizing the carbon impact of serverless functions becomes crucial. The unique characteristics of serverless functions, such as event-driven invocation, pay-as-you-go billing model, short execution duration, ephemeral runtime, and opaque underlying infrastructure, pose challenges in effective carbon metering. In this paper, we argue that the current carbon estimation methodologies should be expanded for more accurate carbon accounting in serverless settings, and propose a usage and allocation-based carbon model that aligns with the context of serverless computing. We also articulate how current serverless systems and billing models do not make it financially attractive to prioritize sustainability for a broad class of users and developers. To solve this, we propose a new carbon-aware pricing model and evaluate its ability to incentivize sustainable practices for developers through better alignment of billing and carbon efficiency.},
  langid = {english},
}

@article{mokhtariDigitalSustainabilityInvolving,
  title = {Towards {{Digital Sustainability}}: {{Involving Cloud Users}} as {{Key Players}}},
  author = {Mokhtari, Anas and Jonglez, Baptiste and Ledoux, Thomas},
  URL = {https://hal.science/hal-04633237},
  urldate = {2024-09-20},
  BOOKTITLE = {{IC2E 2024 - 12th IEEE International Conference on Cloud Engineering}},
  ADDRESS = {Paphos, Cyprus},
  PUBLISHER = {{IEEE}},
  YEAR = {2024},
  MONTH = Sep,
  KEYWORDS = {Cloud computing ; Human-centered computing ; Digital sustainability ; Carbon footprint ; Green energy},
  abstract = {Due to the rapid growth of Cloud services, data centers have become major energy consumers, resulting in significant CO2 emissions. Several infrastructure-focused strategies, such as resource consolidation, have been used to reduce the carbon footprint of Cloud infrastructure. However, end-users are often left out of the picture. Since they are the primary target of Cloud applications, it would be beneficial to actively involve them in reducing the carbon footprint of Cloud applications.},
  langid = {english},
}

% PrÃ©diction
@article{bauerTimeSeriesForecasting2020,
	title        = {Time {{Series Forecasting}} for {{Self-Aware Systems}}},
	author       = {Bauer, Andre and Zufle, Marwin and Herbst, Nikolas and Zehe, Albin and Hotho, Andreas and Kounev, Samuel},
	year         = 2020,
	month        = jul,
	journal      = {Proceedings of the IEEE},
	volume       = 108,
	number       = 7,
	pages        = {1068--1093},
	doi          = {10.1109/JPROC.2020.2983857},
	issn         = {0018-9219, 1558-2256},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Modern distributed systems and Internet-of-Things applications are governed by fast living and changing requirements. Moreover, they have to struggle with huge amounts of data that they create or have to process. To improve the self-awareness of such systems and enable proactive and autonomous decisions, reliable time series forecasting methods are required. However, selecting a suitable forecasting method for a given scenario is a challenging task. According to the ``No-Free-Lunch Theorem,'' there is no general forecasting method that always performs best. Thus, manual feature engineering remains to be a mandatory expert task to avoid trial and error. Furthermore, determining the expected time-to-result of existing forecasting methods is a challenge. In this article, we extensively assess the state-of-the-art in time series forecasting. We compare existing methods and discuss the issues that have to be addressed to enable their use in a self-aware computing context. To address these issues, we present a step-by-step approach to fully automate the feature engineering and forecasting process. Then, following the principles from benchmarking, we establish a level-playing field for evaluating the accuracy and time-to-result of automated forecasting methods for a broad set of application scenarios. We provide results of a benchmarking competition to guide in selecting and appropriately using existing forecasting methods for a given self-aware computing context. Finally, we present a case study in the area of self-aware data-center resource management to exemplify the benefits of fully automated learning and reasoning processes on time series data.},
	langid       = {english}
}
@misc{eismannSizelessPredictingOptimal2021,
	title        = {Sizeless: predicting the optimal size of serverless functions},
	author       = {Eismann, Simon and Bui, Long and Grohmann, Johannes and Abad, Cristina and Herbst, Nikolas and Kounev, Samuel},
	year         = 2021,
	booktitle    = {Proceedings of the 22nd International Middleware Conference},
	location     = {Qu\'{e}bec city, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {Middleware '21},
	pages        = {248â€“259},
	doi          = {10.1145/3464298.3493398},
	isbn         = 9781450385343,
	abstract     = {Serverless functions are an emerging cloud computing paradigm that is being rapidly adopted by both industry and academia. In this cloud computing model, the provider opaquely handles resource management tasks such as resource provisioning, deployment, and auto-scaling. The only resource management task that developers are still in charge of is selecting how much resources are allocated to each worker instance. However, selecting the optimal size of serverless functions is quite challenging, so developers often neglect it despite its significant cost and performance benefits. Existing approaches aiming to automate serverless functions resource sizing require dedicated performance tests, which are time-consuming to implement and maintain.In this paper, we introduce an approach to predict the optimal resource size of a serverless function using monitoring data from a single resource size. As our approach does not require dedicated performance tests, it enables cloud providers to implement resource sizing on a platform level and automate the last resource management task associated with serverless functions. We evaluate our approach on four different serverless applications on AWS, where it predicts the execution time of the other memory sizes based on monitoring data for a single memory size with an average prediction error of 15.3\%. Based on these predictions, it selects the optimal memory size for 79.0\% of the serverless functions and the second-best memory size for 12.3\% of the serverless functions, which results in an average speedup of 39.7\% while also decreasing average costs by 2.6\%.},
	numpages     = 12
}
@misc{leeSPESOptimizingPerformanceResource2024a,
	title        = {{{SPES}}: {{Towards Optimizing Performance-Resource Trade-Off}} for {{Serverless Functions}}},
	shorttitle   = {{SPES}},
	author       = {Lee, Cheryl and Zhu, Zhouruixin and Yang, Tianyi and Huo, Yintong and Su, Yuxin and He, Pinjia and Lyu, Michael R.},
	year         = 2024,
	month        = mar,
	publisher    = {arXiv},
	number       = {arXiv:2403.17574},
	doi          = {10.48550/arXiv.2403.17574},
	eprint       = {2403.17574},
	primaryclass = {cs},
	abstract     = {As an emerging cloud computing deployment paradigm, serverless computing is gaining traction due to its efficiency and ability to harness on-demand cloud resources. However, a significant hurdle remains in the form of the cold start problem, causing latency when launching new function instances from scratch. Existing solutions tend to use oversimplistic strategies for function pre-loading/unloading without full invocation pattern exploitation, rendering unsatisfactory optimization of the trade-off between cold start latency and resource waste. To bridge this gap, we propose SPES, the first differentiated scheduler for runtime cold start mitigation by optimizing serverless function provision. Our insight is that the common architecture of serverless systems prompts the concentration of certain invocation patterns, leading to predictable invocation behaviors. This allows us to categorize functions and pre-load/unload proper function instances with finer-grained strategies based on accurate invocation prediction. Experiments demonstrate the success of SPES in optimizing serverless function provision on both sides: reducing the 75th-percentile cold start rates by 49.77\% and the wasted memory time by 56.43\%, compared to the state-of-the-art. By mitigating the cold start issue, SPES is a promising advancement in facilitating cloud services deployed on serverless architectures.},
	archiveprefix = {arxiv},
	langid       = {english},
	keywords     = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Software Engineering}
}
@article{parkGraphNeuralNetworkBased2024,
	title        = {Graph {{Neural Network-Based SLO-Aware Proactive Resource Autoscaling Framework}} for {{Microservices}}},
	author       = {Park, Jinwoo and Choi, Byungkwon and Lee, Chunghan and Han, Dongsu},
	year         = 2024,
	journal      = {IEEE/ACM Transactions on Networking},
	pages        = {1--16},
	doi          = {10.1109/TNET.2024.3393427},
	issn         = {1063-6692, 1558-2566},
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Microservice is an architectural style widely adopted in various latency-sensitive cloud applications. Similar to the monolith, autoscaling has attracted the attention of operators for managing the resource utilization of microservices. However, it is still challenging to optimize resources in terms of latency service-level-objective (SLO) without human intervention. In this paper, we present GRAF, a graph neural networkbased SLO-aware proactive resource autoscaling framework for minimizing total CPU resources while satisfying latency SLO. GRAF leverages front-end workload, distributed tracing data, and machine learning approaches to (a) observe/estimate the impact of traffic change (b) find optimal resource combinations (c) make proactive resource allocation. Experiments using various open-source benchmarks demonstrate that GRAF successfully targets latency SLO while saving up to 19\% of total CPU resources compared to the fine-tuned autoscaler. GRAF also handles a traffic surge with 36\% fewer resources while achieving up to 2.6x faster tail latency convergence compared to the Kubernetes autoscaler. Moreover, we verify the scalability of GRAF on large-scale deployments, where GRAF saves 21.6\% and 25.4\% for CPU resources and memory resources, respectively.},
	langid       = {english}
}
@inproceedings{handaouiReLeaSERReinforcementLearning2020,
  title = {{{ReLeaSER}}: {{A Reinforcement Learning Strategy}} for {{Optimizing Utilization Of Ephemeral Cloud Resources}}},
  shorttitle = {{{ReLeaSER}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Cloud Computing Technology}} and {{Science}} ({{CloudCom}})},
  author = {Handaoui, Mohamed and Dartois, Jean-Emile and Boukhobza, Jalil and Barais, Olivier and {d'Orazio}, Laurent},
  year = {2020},
  month = dec,
  pages = {65--73},
  publisher = {IEEE},
  address = {Bangkok, Thailand},
  doi = {10.1109/CloudCom49646.2020.00009},
  abstract = {Cloud data center capacities are over-provisioned to handle demand peaks and hardware failures which leads to low resources' utilization. One way to improve resource utilization and thus reduce the total cost of ownership is to offer unused resources (referred to as ephemeral resources) at a lower price. However, reselling resources needs to meet the expectations of its customers in terms of Quality of Service. The goal is so to maximize the amount of reclaimed resources while avoiding SLA penalties. To achieve that, cloud providers have to estimate their future utilization to provide availability guarantees. The prediction should consider a safety margin for resources to react to unpredictable workloads. The challenge is to find the safety margin that provides the best trade-off between the amount of resources to reclaim and the risk of SLA violations. Most state-of-the-art solutions consider a fixed safety margin for all types of metrics (e.g., CPU, RAM). However, a unique fixed margin does not consider various workloads variations over time which may lead to SLA violations or/and poor utilization. In order to tackle these challenges, we propose ReLeaSER, a Reinforcement Learning strategy for optimizing the ephemeral resources' utilization in the cloud. ReLeaSER dynamically tunes the safety margin at the host-level for each resource metric. The strategy learns from past prediction errors (that caused SLA violations). Our solution reduces significantly the SLA violation penalties on average by 2.7{\texttimes} and up to 3.4{\texttimes}. It also improves considerably the CPs' potential savings by 27.6\% on average and up to 43.6\%.},
  isbn = {978-1-66540-388-7},
  langid = {english},
}
%% Ajouts limites

% Passage Ã  l'Ã©chelle
@inproceedings{rzadcaAutopilotWorkloadAutoscaling2020,
	title        = {Autopilot: Workload Autoscaling at {{Google}}},
	shorttitle   = {Autopilot},
	author       = {Rzadca, Krzysztof and Findeisen, Pawel and Swiderski, Jacek and Zych, Przemyslaw and Broniek, Przemyslaw and Kusmierek, Jarek and Nowak, Pawel and Strack, Beata and Witusowski, Piotr and Hand, Steven and Wilkes, John},
	year         = 2020,
	month        = apr,
	booktitle    = {Proceedings of the {{Fifteenth European Conference}} on {{Computer Systems}}},
	publisher    = {ACM},
	address      = {Heraklion Greece},
	pages        = {1--16},
	doi          = {10.1145/3342195.3387524},
	isbn         = {978-1-4503-6882-7},
	abstract     = {In many public and private Cloud systems, users need to specify a limit for the amount of resources (CPU cores and RAM) to provision for their workloads. A job that exceeds its limits might be throttled or killed, resulting in delaying or dropping end-user requests, so human operators naturally err on the side of caution and request a larger limit than the job needs. At scale, this results in massive aggregate resource wastage.},
	langid       = {english}
}
%%%% Horizontal
@inproceedings{al-faresHederaDynamicFlow,
	title        = {Hedera: {{Dynamic Flow Scheduling}} for {{Data Center Networks}}},
	author       = {{Al-Fares}, Mohammad and Radhakrishnan, Sivasankar and Raghavan, Barath and Huang, Nelson and Vahdat, Amin},
	year         = 2010,
	month        = apr,
	booktitle    = {7th USENIX Symposium on Networked Systems Design and Implementation (NSDI 10)},
	publisher    = {USENIX Association},
	address      = {San Jose, CA},
	abstract     = {Today's data centers offer tremendous aggregate bandwidth to clusters of tens of thousands of machines. However, because of limited port densities in even the highest-end switches, data center topologies typically consist of multi-rooted trees with many equal-cost paths between any given pair of hosts. Existing IP multipathing protocols usually rely on per-flow static hashing and can cause substantial bandwidth losses due to longterm collisions.},
	langid       = {english},
    url          = {https://www.usenix.org/conference/nsdi10-0/hedera-dynamic-flow-scheduling-data-center-networks},
    urldate      = {2024-09-18},
}
@article{lakshmanCassandraDecentralizedStructured2010,
	title        = {Cassandra: A Decentralized Structured Storage System},
	shorttitle   = {Cassandra},
	author       = {Lakshman, Avinash and Malik, Prashant},
	year         = 2010,
	month        = apr,
	journal      = {ACM SIGOPS Operating Systems Review},
	volume       = 44,
	number       = 2,
	pages        = {35--40},
	doi          = {10.1145/1773912.1773922},
	issn         = {0163-5980},
	abstract     = {Cassandra is a distributed storage system for managing very large amounts of structured data spread out across many commodity servers, while providing highly available service with no single point of failure. Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different data centers). At this scale, small and large components fail continuously. The way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. While in many ways Cassandra resembles a database and shares many design and implementation strategies therewith, Cassandra does not support a full relational data model; instead, it provides clients with a simple data model that supports dynamic control over data layout and format. Cassandra system was designed to run on cheap commodity hardware and handle high write throughput while not sacrificing read efficiency.},
	langid       = {english}
}
@inproceedings{weilCephScalableHighPerformance,
	title        = {Ceph: {{A Scalable}}, {{High-Performance Distributed File System}}},
	author       = {Weil, Sage A and Brandt, Scott A and Miller, Ethan L and Long, Darrell D E and Maltzahn, Carlos},
	year         = 2006,
	month        = nov,
	booktitle    = {7th USENIX Symposium on Operating Systems Design and Implementation (OSDI 06)},
	publisher    = {USENIX Association},
	address      = {Seattle, WA},
    url          = {https://www.usenix.org/conference/osdi-06/ceph-scalable-high-performance-distributed-file-system},
    urldate      = {2024-09-18},
	abstract     = {We have developed Ceph, a distributed file system that provides excellent performance, reliability, and scalability. Ceph maximizes the separation between data and metadata management by replacing allocation tables with a pseudo-random data distribution function (CRUSH) designed for heterogeneous and dynamic clusters of unreliable object storage devices (OSDs). We leverage device intelligence by distributing data replication, failure detection and recovery to semi-autonomous OSDs running a specialized local object file system. A dynamic distributed metadata cluster provides extremely efficient metadata management and seamlessly adapts to a wide range of general purpose and scientific computing file system workloads. Performance measurements under a variety of workloads show that Ceph has excellent I/O performance and scalable metadata management, supporting more than 250,000 metadata operations per second.},
	langid       = {english}
}
%%%% Vertical
@inproceedings{boyd-wickizerAnalysisLinuxScalability,
	title        = {An {{Analysis}} of {{Linux Scalability}} to {{Many Cores}}},
	author       = {{Boyd-Wickizer}, Silas and Clements, Austin T and Mao, Yandong and Pesterev, Aleksey and Kaashoek, M Frans and Morris, Robert and Zeldovich, Nickolai},
	year         = 2010,
	month        = oct,
	booktitle    = {9th USENIX Symposium on Operating Systems Design and Implementation (OSDI 10)},
	publisher    = {USENIX Association},
	address      = {Vancouver, BC},
	abstract     = {This paper analyzes the scalability of seven system applications (Exim, memcached, Apache, PostgreSQL, gmake, Psearchy, and MapReduce) running on Linux on a 48core computer. Except for gmake, all applications trigger scalability bottlenecks inside a recent Linux kernel. Using mostly standard parallel programming techniques---this paper introduces one new technique, sloppy counters---these bottlenecks can be removed from the kernel or avoided by changing the applications slightly. Modifying the kernel required in total 3002 lines of code changes. A speculative conclusion from this analysis is that there is no scalability reason to give up on traditional operating system organizations just yet.},
	langid       = {english},
    url          = {https://www.usenix.org/conference/osdi10/analysis-linux-scalability-many-cores},
    urldate      = {2024-09-18},
}
@inproceedings{linderOracleParallelRDBMS1993,
	title        = {Oracle Parallel {{RDBMS}} on Massively Parallel Systems},
	author       = {Linder, B.},
	year         = 1993,
	booktitle    = {[1993] {{Proceedings}} of the {{Second International Conference}} on {{Parallel}} and {{Distributed Information Systems}}},
	publisher    = {IEEE Comput. Soc. Press},
	address      = {San Diego, CA, USA},
	pages        = {67--68},
	doi          = {10.1109/PDIS.1993.253071},
	isbn         = {978-0-8186-3330-0},
	abstract     = {Over the past ten years data storage systems in both the commercial and scientific realms have experienced what can be called an "Information Explosion." This exponential increase in the demand for storage and access to data is the result of fundamental changes in the economics of underlying technologies. The speed and accuracy of data collection has more than doubled. The speed of data transmission has risen an order of magnitude while price has halved. The cost per megabyte of permanent storage has dropped by an order of magnitude. Client desktop computers have gone from .5 MIPS to 100 MIPS. These underlying factors have created user demands for data servers of unprecedented proportions. Oracle relational database technology implemented on Massively Parallel hardware architectures allows both OLTP and Decsision support on the same database image. Both queries and transaction processing power scale linearly on MPP platforms. This technology delivers scalable RDBMS super-servers.},
	langid       = {english}
}
@article{xian-hesunScalabilityParallelAlgorithmmachine1994,
	title        = {Scalability of Parallel Algorithm-Machine Combinations},
	author       = {{Xian-He Sun} and Rover, D.T.},
	year         = 1994,
	month        = jun,
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	volume       = 5,
	number       = 6,
	pages        = {599--613},
	doi          = {10.1109/71.285606},
	issn         = 10459219,
	copyright    = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	abstract     = {Scalability has become an important consideration in parallel algorithm and machine designs. The word scalable, or scalability, has been widely and often used in the parallel processingcommunity. However, there is no adequate, commonly accepted definition of scalability available. Scalabilities of computer systems and programs are difficult to quantify, evaluate, and compare. In this paper, scalability is formally defined for algorithm-machine combinations.A practical method is proposed to provide a quantitative measurement of the scalability. The relationbetween the newly proposed scalability and other existing parallel performance metrics is studied. A harmony between speedup and scalability has been observed. Theoretical results show that a large class of algorithm-machine combinations is scalable and the scalability can be predictedthrough premeasured machine parameters. Two algorithms have been studied on an ,)CUBE 2 mullicomputer and on a MasPar MP-1 computer. These case studies have shown how scalabilitiescan be measured, computed,and predicted.Performanceinstrumentationand visualization tools also have been used and developed to understand the scalability related behavior.},
	langid       = {english}
}
@inproceedings{straesserPowerApplicationsVision2023,
	title        = {Power to the {{Applications}}: {{The Vision}} of {{Continuous Decentralized Autoscaling}}},
	shorttitle   = {Power to the {{Applications}}},
	author       = {Straesser, Martin and Gei{\ss}ler, Stefan and Ho{\ss}feld, Tobias and Kounev, Samuel},
	year         = 2023,
	month        = may,
	booktitle    = {2023 {{IEEE}}/{{ACM}} 23rd {{International Symposium}} on {{Cluster}}, {{Cloud}} and {{Internet Computing Workshops}} ({{CCGridW}})},
	publisher    = {IEEE},
	address      = {Bangalore, India},
	pages        = {281--283},
	doi          = {10.1109/CCGridW59191.2023.00058},
	isbn         = 9798350302080,
	copyright    = {https://doi.org/10.15223/policy-029},
	abstract     = {Autoscaling has been one of the most active research areas since the beginning of the cloud computing era. Nearly all previously proposed approaches focus on decision-making based on averaged monitoring values of many service instances at fixed points in time. This limits responsiveness and can lead to service level objective (SLO) violations when the load suddenly increases. Our vision of continuous decentralized autoscaling avoids these issues by giving individual service instances the power to make scaling decisions in a distributed fashion. Each instance performs self-monitoring and evaluates its state. The service instance initiates upscaling if it detects an overload or downscaling if its load is below a specified threshold. By randomly determining scaling timing, we achieve quasi-continuous scaling behavior when multiple service instances are deployed. We discuss challenges regarding analytical modeling, simulation, and real-world evaluation of this approach.},
	langid       = {english}
}
%% Ajouts sÃ©cu (Quentin)
@inproceedings{gruss2016rowhammer,
	title        = {{Rowhammer.js}: a remote software-induced fault attack in {JavaScript}},
	author       = {Gruss, Daniel and Maurice, Cl{\'e}mentine and Mangard, Stefan},
	year         = 2016,
	booktitle    = {Proceedings of the 13th International conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA'16)},
	publisher    = {Springer},
	pages        = {300--321},
	doi          = {10.1007/978-3-319-40667-1_15}
}
@inproceedings{lipp2018meltdown,
    author = {Moritz Lipp and Michael Schwarz and Daniel Gruss and Thomas Prescher and Werner Haas and Anders Fogh and Jann Horn and Stefan Mangard and Paul Kocher and Daniel Genkin and Yuval Yarom and Mike Hamburg},
    title = {Meltdown: Reading Kernel Memory from User Space},
    booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
    year = {2018},
    isbn = {978-1-939133-04-5},
    address = {Baltimore, MD},
    pages = {973--990},
    url = {https://www.usenix.org/conference/usenixsecurity18/presentation/lipp},
    urldate = {2024-09-18},
    publisher = {USENIX Association},
    month = aug
}
@inproceedings{kocher2019spectre,
	title        = {{Spectre} attacks: exploiting speculative execution},
	author       = {Kocher, Paul and Horn, Jann and Fogh, Anders and Genkin, Daniel and Gruss, Daniel and Haas, Werner and Hamburg, Mike and Lipp, Moritz and Mangard, Stefan and Prescher, Thomas and others},
	year         = 2019,
	booktitle    = {Proceedings of the 40th {IEEE} Symposium on Security and Privacy (S\&P'19)},
	publisher    = {IEEE},
	pages        = {1--19},
	doi          = {10.1109/sp.2019.00002}
}
@inproceedings{pedersen2017trash,
	title        = {From trash to treasure: timing-sensitive garbage collection},
	author       = {Pedersen, Mathias V and Askarov, Aslan},
	year         = 2017,
	booktitle    = {Proceedings of the 38th {IEEE} Symposium on Security and Privacy (S\&P'17)},
	publisher    = {IEEE},
	pages        = {693--709},
	doi          = {10.1109/sp.2017.64}
}
@inproceedings{wu2018side,
    author = {Xiaofeng Wu and Kun Suo and Yong Zhao and Jia Rao},
    title = {A Side-channel Attack on {HotSpot} Heap Management},
    booktitle = {10th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 18)},
    year = {2018},
    address = {Boston, MA},
    url = {https://www.usenix.org/conference/hotcloud18/presentation/wu},
    urldate = {2024-09-18},
    publisher = {USENIX Association},
    month = jul
}
@inproceedings{cui2021smashex,
	title        = {{SmashEx}: Smashing {SGX} Enclaves Using Exceptions},
	author       = {Cui, Jinhua and Yu, Jason Zhijingcheng and Shinde, Shweta and Saxena, Prateek and Cai, Zhiping},
	year         = 2021,
	booktitle    = {Proceedings of the 28th {ACM} {SIGSAC} Conference on Computer and Communications Security (CCS'21)},
	publisher    = {ACM},
	pages        = {779--793},
	doi          = {10.1145/3460120.3484821}
}
